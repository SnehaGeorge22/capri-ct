{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa33ecbf",
   "metadata": {},
   "source": [
    "## CNN Baseline Non Causal Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7c8218e",
   "metadata": {},
   "source": [
    "The non-causal baseline model is used as a reference point to compare against the causal-aware Capri-CT model. Unlike Capri-CT, which integrates causal reasoning to understand how interventions affect outcomes, the baseline model relies solely on correlational patterns in the data without explicitly modeling causal relationships.\n",
    "\n",
    "This baseline typically consists of a convolutional neural network (CNN) that processes image data alongside metadata inputs such as voltage, time, and agent type. It predicts outcomes like Signal-to-Noise Ratio (SNR) based on observed features, without accounting for causal interventions.\n",
    "\n",
    "While effective at capturing associations, the non-causal baseline lacks robustness to changes caused by interventions or shifts in the data distribution. Therefore, it provides a meaningful benchmark to demonstrate the advantages of causal-aware models like Capri-CT in terms of interpretability, generalization, and handling of counterfactual scenarios.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a51bc958",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################################\n",
    "# Importing the required libraries for our CNN Baseline Non - Causal Model\n",
    "######################################################################################\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image\n",
    "import random\n",
    "import time as T\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data import Subset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pathlib import Path\n",
    "from sklearn.metrics import mean_absolute_error,mean_squared_error, r2_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a9f8cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################################\n",
    "# Below is the Class CTDataset \n",
    "# Combining the CT image with the metadata using Dataset package\n",
    "# for SNR prediction\n",
    "##########################################################################################\n",
    "\n",
    "class CTDataset(Dataset):\n",
    "    \"\"\"\n",
    "    PyTorch Dataset for loading CT scan images and associated metadata.\n",
    "\n",
    "    Args:\n",
    "        metadata_csv (str or Path): Path to the CSV file containing metadata.\n",
    "        img_folder_path (str or Path): Directory containing CT scan image files.\n",
    "        transform (callable, optional): Transformations to apply to the images.\n",
    "\n",
    "    Attributes:\n",
    "        img_data (pd.DataFrame): DataFrame containing the metadata.\n",
    "        img_folder (Path): Path to the image folder.\n",
    "        transform (callable or None): Optional transform to apply to images.\n",
    "\n",
    "    Methods:\n",
    "        __getitem__(idx): Returns a single data sample consisting of:\n",
    "            - transformed image tensor (grayscale),\n",
    "            - one-hot encoded agent vector (tensor),\n",
    "            - voltage (tensor),\n",
    "            - time (tensor),\n",
    "            - CNR (tensor),\n",
    "            - SNR (tensor).\n",
    "        __len__(): Returns the total number of samples.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, metadata_csv, img_folder_path, transform=None):\n",
    "        self.img_data = pd.read_csv(metadata_csv)\n",
    "        self.img_folder = img_folder_path\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.img_data.iloc[idx]\n",
    "        img = Image.open(os.path.join(self.img_folder, row['Filename'])).convert('L')\n",
    "        if self.transform:\n",
    "            image = self.transform(img)\n",
    "\n",
    "        agent_dict = {'Iodine': 0, 'BiNPs 50nm': 1, 'BiNPs 100nm': 2}\n",
    "        agent_vector = torch.zeros(len(agent_dict))\n",
    "        agent_vector[agent_dict[row['Classification']]] = 1\n",
    "\n",
    "        voltage = torch.tensor([row['Voltage']], dtype=torch.float32)\n",
    "        time = torch.tensor([row['Time']], dtype=torch.float32)\n",
    "        cnr = torch.tensor([row['CNR']], dtype=torch.float32)\n",
    "        snr = torch.tensor([row['SNR']], dtype=torch.float32)\n",
    "\n",
    "        return image, agent_vector, voltage, time, cnr, snr\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7238fba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################################\n",
    "# Below is our  CNN(Convolutional Neural Network) Baseline Non - Causal Model\n",
    "#################################################################################\n",
    "\n",
    "class CNNBaselineModel(nn.Module):\n",
    "    \"\"\"\n",
    "    Convolutional Neural Network baseline model for predicting SNR from CT images and metadata.\n",
    "\n",
    "    Args:\n",
    "        image_channels (int): Number of input image channels. Default is 1 (grayscale).\n",
    "        input_dim (int): Dimension of metadata input vector (e.g., voltage, time, agent one-hot). Default is 5.\n",
    "\n",
    "    Architecture:\n",
    "        - Three convolutional layers with ReLU activations and max pooling.\n",
    "        - Adaptive average pooling to reduce spatial dimensions to (1, 1).\n",
    "        - Fully connected layers combining flattened CNN features and metadata.\n",
    "        - Two separate output heads for multi-task learning:\n",
    "            * SNR prediction (main task)\n",
    "            * CNR prediction (auxiliary task)\n",
    "\n",
    "    Methods:\n",
    "        forward(image, agent_vector, voltage, time):\n",
    "            Performs a forward pass through the model.\n",
    "            \n",
    "            Args:\n",
    "                image (Tensor): Input image tensor of shape (B, C, H, W).\n",
    "                agent_vector (Tensor): One-hot encoded agent vector of shape (B, N).\n",
    "                voltage (Tensor): Voltage feature tensor of shape (B, 1).\n",
    "                time (Tensor): Time feature tensor of shape (B, 1).\n",
    "            \n",
    "            Returns:\n",
    "                snr_out (Tensor): Predicted SNR values (B, 1).\n",
    "                cnr_out (Tensor): Predicted CNR values (B, 1).\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, image_channels=1, input_dim=5):  \n",
    "        super(CNNBaselineModel, self).__init__()\n",
    "\n",
    "        # CNN layers\n",
    "        self.conv1 = nn.Conv2d(image_channels, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.adaptive_pool = nn.AdaptiveAvgPool2d((1, 1))  # (B, 128, 1, 1)\n",
    "\n",
    "        # Fully connected layers after flattening CNN features + metadata\n",
    "        self.fc1 = nn.Linear(128 + input_dim, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "\n",
    "        # Two separate heads for multi-task output\n",
    "        self.fc_snr = nn.Linear(128, 1)  \n",
    "        self.fc_cnr = nn.Linear(128, 1) \n",
    "\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight)\n",
    "                nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, image, agent_vector, voltage, time):\n",
    "        x = F.relu(self.conv1(image))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "\n",
    "        x = self.adaptive_pool(x)  # (B, 128, 1, 1)\n",
    "        x = torch.flatten(x, 1)    # (B, 128)\n",
    "\n",
    "        # Metadata \n",
    "        meta_input = torch.cat([voltage, time, agent_vector], dim=1)  # (B, 5)\n",
    "\n",
    "        combined = torch.cat([x, meta_input], dim=1)  # (B, 128 + 5)\n",
    "\n",
    "        x = F.relu(self.fc1(combined))\n",
    "        x = F.relu(self.fc2(x))\n",
    "\n",
    "        # Multi-task outputs\n",
    "        snr_out = self.fc_snr(x)\n",
    "        cnr_out = self.fc_cnr(x)\n",
    "\n",
    "        return snr_out, cnr_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe0c720f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################################\n",
    "# This method trains the baseline CNN model with the given model hyperparameters\n",
    "#################################################################################\n",
    "\n",
    "def train_model(model, train_loader, val_loader, num_epochs=150, lr=1e-3, patience=3):\n",
    "    \"\"\"\n",
    "    Train the given model using training and validation data loaders with early stopping.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The PyTorch model to train.\n",
    "        train_loader (DataLoader): DataLoader for the training dataset.\n",
    "        val_loader (DataLoader): DataLoader for the validation dataset.\n",
    "        num_epochs (int, optional): Maximum number of training epochs. Default is 150.\n",
    "        lr (float, optional): Learning rate for the optimizer. Default is 1e-3.\n",
    "        patience (int, optional): Number of epochs with no improvement on validation loss before stopping early. Default is 3.\n",
    "\n",
    "    Returns:\n",
    "        float: Total training time in seconds.\n",
    "\n",
    "    Description:\n",
    "        - Uses Smooth L1 loss for both SNR and CNR predictions.\n",
    "        - Optimizes with AdamW optimizer with weight decay.\n",
    "        - Applies cosine annealing learning rate scheduler.\n",
    "        - Combines losses with a weighting factor alpha (default 0.3)\n",
    "        - Clips gradients to a maximum norm of 1.0 to stabilize training.\n",
    "        - Implements early stopping based on validation loss not improving for 'patience' epochs.\n",
    "    \"\"\"\n",
    "    \n",
    "    criterion = nn.SmoothL1Loss()\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-3)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    start_time = T.time()\n",
    "    alpha = 0.3\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "\n",
    "        for image, agent_vector, voltage, time, cnr, snr in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            snr_pred, cnr_pred = model(image, agent_vector, voltage, time)\n",
    "\n",
    "            loss_snr = criterion(snr_pred, snr)\n",
    "            loss_cnr = criterion(cnr_pred, cnr)\n",
    "\n",
    "            loss = loss_snr + alpha * loss_cnr\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for image, agent_vector, voltage, time, cnr, snr in val_loader:\n",
    "                snr_pred, cnr_pred = model(image, agent_vector, voltage, time)\n",
    "\n",
    "                loss_snr = criterion(snr_pred, snr)\n",
    "                loss_cnr = criterion(cnr_pred, cnr)\n",
    "\n",
    "                loss = loss_snr + alpha * loss_cnr\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        scheduler.step()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {avg_train_loss:.4f}, Validation Loss: {avg_val_loss:.4f}\")\n",
    "\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            print(f\"patience_counter : {patience_counter}\")\n",
    "            if patience_counter >= patience:\n",
    "                print(\"Early stopping triggered.\")\n",
    "                break\n",
    "    end_time = T.time()\n",
    "    total_time = end_time - start_time\n",
    "    print(f\"‚è±Ô∏è Training time for this model: {total_time:.2f} seconds\")\n",
    "    return total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8fbbf3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################\n",
    "# Setting the seed value for each training loop\n",
    "###############################################################\n",
    "\n",
    "def set_seed(seed):\n",
    "    \"\"\"\n",
    "    Sets the random seed across Python, NumPy, and PyTorch (CPU and GPU) for reproducibility.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    seed : int\n",
    "        The seed value to ensure deterministic behavior across runs.\n",
    "    \"\"\"\n",
    "    \n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1348a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################################\n",
    "# get_data_loaders function:\n",
    "# Loads a CT dataset with images and metadata.\n",
    "# Splits the dataset into training and validation sets.\n",
    "# Applies image transformations.\n",
    "############################################################################################\n",
    "\n",
    "def get_data_loaders(seed):\n",
    "    \"\"\"\n",
    "    Prepare and return training and validation DataLoaders for the CTDataset.\n",
    "\n",
    "    Args:\n",
    "        seed (int): Random seed for reproducibility of dataset splitting and shuffling.\n",
    "\n",
    "    Returns:\n",
    "        train_loader (DataLoader): DataLoader for the training dataset subset.\n",
    "        val_loader (DataLoader): DataLoader for the validation dataset subset.\n",
    "\n",
    "    Description:\n",
    "        - Sets manual seed for PyTorch and DataLoader generator to ensure reproducibility.\n",
    "        - Applies image transformations: resizing to 9x9 and conversion to tensor.\n",
    "        - Loads dataset from specified CSV metadata and image folder.\n",
    "        - Splits dataset into training (80%) and validation (20%) subsets using a fixed random seed.\n",
    "        - Creates DataLoaders with batch size 8; training loader is shuffled, validation loader is not.\n",
    "    \"\"\"\n",
    "    torch.manual_seed(seed)  \n",
    "    generator = torch.Generator().manual_seed(seed)\n",
    "    \n",
    "    transform = transforms.Compose([\n",
    "    transforms.Resize((9, 9)),  \n",
    "    transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "    base_path = Path(\"../dataset\")\n",
    "    \n",
    "    \n",
    "    dataset = CTDataset(\n",
    "        metadata_csv= base_path / \"final_dataset.csv\",\n",
    "        img_folder_path= base_path / \"img\" ,\n",
    "        transform=transform\n",
    "    )\n",
    "\n",
    "    # Split\n",
    "    train_indices, val_indices = train_test_split(list(range(len(dataset))), test_size=0.2, random_state=seed)\n",
    "    train_subset = Subset(dataset, train_indices)\n",
    "    val_subset = Subset(dataset, val_indices)\n",
    "\n",
    "    # DataLoaders\n",
    "    train_loader = DataLoader(train_subset, batch_size=8, shuffle=True, generator=generator)\n",
    "    val_loader = DataLoader(val_subset, batch_size=8, shuffle=False)\n",
    "\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a851bb03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################\n",
    "# The below method trains the ensemble models together\n",
    "# it calls the train_single_model method with given parameters\n",
    "#############################################################################\n",
    "\n",
    "base_times = []\n",
    "def train_base_model(num_models=5, base_seed=42):\n",
    "    \"\"\"\n",
    "    Train multiple CNN baseline models with different seeds and return the trained models.\n",
    "\n",
    "    Args:\n",
    "        num_models (int): Number of models to train. Defaults to 5.\n",
    "        base_seed (int): Starting seed for reproducibility. Each model uses base_seed + i.\n",
    "\n",
    "    Returns:\n",
    "        base_models_list (list): List of trained CNNBaselineModel instances.\n",
    "\n",
    "    Description:\n",
    "        - Iterates over num_models, setting a unique seed for each.\n",
    "        - For each seed, initializes a CNNBaselineModel and moves it to CPU.\n",
    "        - Loads training and validation data loaders with the current seed.\n",
    "        - Trains the model and records training time.\n",
    "        - Collects all trained models in a list and returns it.\n",
    "    \"\"\"\n",
    "    base_models_list = []\n",
    "    device = \"cpu\"\n",
    "    for i in range(num_models):\n",
    "        seed = base_seed + i\n",
    "        print(f\"\\nüîÅ Training model {i+1}/{num_models} with seed {seed}\")\n",
    "        set_seed(seed)\n",
    "\n",
    "        image_channels = 1 \n",
    "        base_model = CNNBaselineModel(image_channels=image_channels, input_dim=5).to(device)\n",
    "        \n",
    "        train_loader, val_loader = get_data_loaders(seed)\n",
    "\n",
    "        train_time = train_model(base_model, train_loader, val_loader)\n",
    "        base_times.append(train_time)\n",
    "        base_models_list.append(base_model)\n",
    "\n",
    "    return base_models_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da19739b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################################\n",
    "# This method evaluates the predicted SNR values with the targets values\n",
    "#################################################################################\n",
    "\n",
    "def evaluate_models(ensemble_models, seed, device='cpu'):\n",
    "    \"\"\"\n",
    "    Evaluate an ensemble of models on the validation set and compute mean and std of predictions.\n",
    "\n",
    "    Args:\n",
    "        ensemble_models (list): List of trained models to evaluate.\n",
    "        seed (int): Seed for data loader reproducibility.\n",
    "        device (str): Device to run the evaluation on ('cpu' or 'cuda'). Defaults to 'cpu'.\n",
    "\n",
    "    Returns:\n",
    "        preds_mean (np.ndarray): Mean predictions of the ensemble for each sample.\n",
    "        preds_std (np.ndarray): Standard deviation of the ensemble predictions for each sample.\n",
    "        targets (np.ndarray): Ground truth SNR values from the validation set.\n",
    "\n",
    "    Description:\n",
    "        - Loads validation data using the given seed.\n",
    "        - For each batch, moves data to the specified device.\n",
    "        - Collects predictions from each model in the ensemble without gradient tracking.\n",
    "        - Computes the mean and standard deviation of predictions across the ensemble.\n",
    "        - Aggregates predictions and ground truth targets for all validation samples.\n",
    "    \"\"\"\n",
    "    \n",
    "    train_loader, val_loader = get_data_loaders(seed)\n",
    "\n",
    "    preds_mean, preds_std, targets = [], [], []\n",
    "\n",
    "    for image, agent_vector, voltage, time,cnr,snr in val_loader:\n",
    "        image = image.to(device)\n",
    "        agent_vector = agent_vector.to(device)\n",
    "        voltage = voltage.to(device)\n",
    "        time = time.to(device)\n",
    "        cnr = cnr.to(device)\n",
    "        snr = snr.to(device)\n",
    "\n",
    "        batch_preds = []\n",
    "        with torch.no_grad():\n",
    "            for model in ensemble_models:\n",
    "                model.eval()\n",
    "                model.to(device)\n",
    "                output,_ = model(image, agent_vector, voltage, time)\n",
    "                batch_preds.append(output.cpu())\n",
    "\n",
    "        batch_preds = torch.stack(batch_preds)  # [num_models, B, 1]\n",
    "        mean_pred = batch_preds.mean(dim=0).squeeze().numpy()     # [B, 1]\n",
    "        std_pred = batch_preds.std(dim=0).squeeze().numpy()       # [B, 1]\n",
    "\n",
    "        preds_mean.extend(mean_pred)\n",
    "        preds_std.extend(std_pred)\n",
    "        targets.extend(snr.cpu().numpy())\n",
    "\n",
    "    preds_mean = np.array(preds_mean)\n",
    "    preds_std = np.array(preds_std)\n",
    "    targets = np.array(targets)\n",
    "\n",
    "    return preds_mean, preds_std, targets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8c1d7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################################\n",
    "# This method evaluates the predicted SNR values with the targets values\n",
    "# of Individual models\n",
    "#################################################################################\n",
    "\n",
    "def evaluate_individual_models(ensemble_models, seed, device='cpu'):\n",
    "    \"\"\"\n",
    "    Evaluate each model in an ensemble individually on the validation set and compute regression metrics.\n",
    "\n",
    "    Args:\n",
    "        ensemble_models (list): List of trained models to evaluate.\n",
    "        seed (int): Seed for data loader reproducibility.\n",
    "        device (str): Device to run the evaluation on ('cpu' or 'cuda'). Defaults to 'cpu'.\n",
    "\n",
    "    Returns:\n",
    "        model_metrics (list of dicts): List containing metrics (MAE, RMSE, R2) for each model.\n",
    "\n",
    "    Description:\n",
    "        - Loads validation data using the given seed.\n",
    "        - For each model, moves it to the specified device and sets to evaluation mode.\n",
    "        - Iterates over validation batches, making predictions without gradient computation.\n",
    "        - Collects predictions and ground truth targets.\n",
    "        - Calculates Mean Absolute Error (MAE), Root Mean Squared Error (RMSE), and R¬≤ score for each model.\n",
    "        - Prints the metrics for each model and returns a list summarizing all metrics.\n",
    "    \"\"\"\n",
    "\n",
    "    _, val_loader = get_data_loaders(seed)\n",
    "    \n",
    "    model_metrics = []\n",
    "\n",
    "    for model_index, model in enumerate(ensemble_models):\n",
    "        model.eval()\n",
    "        model.to(device)\n",
    "\n",
    "        all_preds = []\n",
    "        all_targets = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for image, agent_vector, voltage, time, _, snr in val_loader:\n",
    "                image = image.to(device)\n",
    "                agent_vector = agent_vector.to(device)\n",
    "                voltage = voltage.to(device)\n",
    "                time = time.to(device)\n",
    "                snr = snr.to(device)\n",
    "\n",
    "                pred, _ = model(image, agent_vector, voltage, time)\n",
    "                all_preds.extend(pred.squeeze().cpu().numpy())\n",
    "                all_targets.extend(snr.squeeze().cpu().numpy())\n",
    "\n",
    "        # Convert to NumPy arrays\n",
    "        all_preds = np.array(all_preds)\n",
    "        all_targets = np.array(all_targets)\n",
    "\n",
    "        # Compute metrics\n",
    "        mae = mean_absolute_error(all_targets, all_preds)\n",
    "        rmse = np.sqrt(mean_squared_error(all_targets, all_preds))\n",
    "        r2 = r2_score(all_targets, all_preds)\n",
    "\n",
    "        model_metrics.append({\n",
    "            'Model': model_index + 1,\n",
    "            'MAE': mae,\n",
    "            'RMSE': rmse,\n",
    "            'R2': r2\n",
    "        })\n",
    "\n",
    "        print(f\"Model {model_index+1} | MAE: {mae:.3f}, RMSE: {rmse:.3f}, R2: {r2:.3f}\")\n",
    "\n",
    "    return model_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4740c81e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîÅ Training model 1/5 with seed 42\n",
      "Epoch 1/150, Train Loss: 159.2284, Validation Loss: 170.3130\n",
      "Epoch 2/150, Train Loss: 157.1248, Validation Loss: 170.4923\n",
      "patience_counter : 1\n",
      "Epoch 3/150, Train Loss: 155.6950, Validation Loss: 167.2182\n",
      "Epoch 4/150, Train Loss: 151.9552, Validation Loss: 160.7836\n",
      "Epoch 5/150, Train Loss: 145.9545, Validation Loss: 152.8650\n",
      "Epoch 6/150, Train Loss: 140.9492, Validation Loss: 173.6997\n",
      "patience_counter : 1\n",
      "Epoch 7/150, Train Loss: 132.5173, Validation Loss: 138.0866\n",
      "Epoch 8/150, Train Loss: 126.2785, Validation Loss: 131.3831\n",
      "Epoch 9/150, Train Loss: 124.1043, Validation Loss: 128.1587\n",
      "Epoch 10/150, Train Loss: 115.2055, Validation Loss: 114.3625\n",
      "Epoch 11/150, Train Loss: 109.7634, Validation Loss: 127.5375\n",
      "patience_counter : 1\n",
      "Epoch 12/150, Train Loss: 107.3180, Validation Loss: 112.2695\n",
      "Epoch 13/150, Train Loss: 105.7968, Validation Loss: 109.7242\n",
      "Epoch 14/150, Train Loss: 105.2045, Validation Loss: 104.7327\n",
      "Epoch 15/150, Train Loss: 105.1341, Validation Loss: 108.6510\n",
      "patience_counter : 1\n",
      "Epoch 16/150, Train Loss: 109.0778, Validation Loss: 108.1449\n",
      "patience_counter : 2\n",
      "Epoch 17/150, Train Loss: 109.4845, Validation Loss: 103.3564\n",
      "Epoch 18/150, Train Loss: 103.5081, Validation Loss: 112.8940\n",
      "patience_counter : 1\n",
      "Epoch 19/150, Train Loss: 106.4839, Validation Loss: 103.5054\n",
      "patience_counter : 2\n",
      "Epoch 20/150, Train Loss: 102.7849, Validation Loss: 100.0192\n",
      "Epoch 21/150, Train Loss: 102.8849, Validation Loss: 108.1837\n",
      "patience_counter : 1\n",
      "Epoch 22/150, Train Loss: 101.3246, Validation Loss: 100.5036\n",
      "patience_counter : 2\n",
      "Epoch 23/150, Train Loss: 102.1576, Validation Loss: 99.9098\n",
      "Epoch 24/150, Train Loss: 100.2203, Validation Loss: 102.0678\n",
      "patience_counter : 1\n",
      "Epoch 25/150, Train Loss: 104.0011, Validation Loss: 101.4655\n",
      "patience_counter : 2\n",
      "Epoch 26/150, Train Loss: 101.4031, Validation Loss: 104.7028\n",
      "patience_counter : 3\n",
      "Early stopping triggered.\n",
      "‚è±Ô∏è Training time for this model: 218.81 seconds\n",
      "\n",
      "üîÅ Training model 2/5 with seed 43\n",
      "Epoch 1/150, Train Loss: 160.6400, Validation Loss: 159.2439\n",
      "Epoch 2/150, Train Loss: 160.8209, Validation Loss: 161.7780\n",
      "patience_counter : 1\n",
      "Epoch 3/150, Train Loss: 157.1779, Validation Loss: 154.4735\n",
      "Epoch 4/150, Train Loss: 152.8079, Validation Loss: 150.3793\n",
      "Epoch 5/150, Train Loss: 144.2629, Validation Loss: 138.2924\n",
      "Epoch 6/150, Train Loss: 136.2825, Validation Loss: 132.5953\n",
      "Epoch 7/150, Train Loss: 133.5565, Validation Loss: 129.4248\n",
      "Epoch 8/150, Train Loss: 124.8381, Validation Loss: 121.8123\n",
      "Epoch 9/150, Train Loss: 119.6639, Validation Loss: 116.7806\n",
      "Epoch 10/150, Train Loss: 112.6530, Validation Loss: 119.1814\n",
      "patience_counter : 1\n",
      "Epoch 11/150, Train Loss: 114.1159, Validation Loss: 129.0593\n",
      "patience_counter : 2\n",
      "Epoch 12/150, Train Loss: 111.4654, Validation Loss: 102.4300\n",
      "Epoch 13/150, Train Loss: 106.8968, Validation Loss: 117.4217\n",
      "patience_counter : 1\n",
      "Epoch 14/150, Train Loss: 108.5931, Validation Loss: 109.8988\n",
      "patience_counter : 2\n",
      "Epoch 15/150, Train Loss: 106.8838, Validation Loss: 95.6189\n",
      "Epoch 16/150, Train Loss: 103.3470, Validation Loss: 96.9645\n",
      "patience_counter : 1\n",
      "Epoch 17/150, Train Loss: 103.7485, Validation Loss: 118.1007\n",
      "patience_counter : 2\n",
      "Epoch 18/150, Train Loss: 105.3283, Validation Loss: 99.5969\n",
      "patience_counter : 3\n",
      "Early stopping triggered.\n",
      "‚è±Ô∏è Training time for this model: 138.84 seconds\n",
      "\n",
      "üîÅ Training model 3/5 with seed 44\n",
      "Epoch 1/150, Train Loss: 156.2138, Validation Loss: 178.7415\n",
      "Epoch 2/150, Train Loss: 155.2989, Validation Loss: 179.6389\n",
      "patience_counter : 1\n",
      "Epoch 3/150, Train Loss: 153.3960, Validation Loss: 173.0121\n",
      "Epoch 4/150, Train Loss: 147.9051, Validation Loss: 166.6582\n",
      "Epoch 5/150, Train Loss: 142.5286, Validation Loss: 157.3781\n",
      "Epoch 6/150, Train Loss: 131.8726, Validation Loss: 146.3419\n",
      "Epoch 7/150, Train Loss: 125.4017, Validation Loss: 138.3193\n",
      "Epoch 8/150, Train Loss: 120.7249, Validation Loss: 170.9000\n",
      "patience_counter : 1\n",
      "Epoch 9/150, Train Loss: 117.1914, Validation Loss: 129.4862\n",
      "Epoch 10/150, Train Loss: 113.1499, Validation Loss: 118.1061\n",
      "Epoch 11/150, Train Loss: 113.4097, Validation Loss: 121.3940\n",
      "patience_counter : 1\n",
      "Epoch 12/150, Train Loss: 107.8204, Validation Loss: 121.2565\n",
      "patience_counter : 2\n",
      "Epoch 13/150, Train Loss: 111.9512, Validation Loss: 114.7180\n",
      "Epoch 14/150, Train Loss: 105.1892, Validation Loss: 120.2135\n",
      "patience_counter : 1\n",
      "Epoch 15/150, Train Loss: 106.1138, Validation Loss: 112.0264\n",
      "Epoch 16/150, Train Loss: 106.0444, Validation Loss: 107.4209\n",
      "Epoch 17/150, Train Loss: 102.3642, Validation Loss: 114.8391\n",
      "patience_counter : 1\n",
      "Epoch 18/150, Train Loss: 105.5208, Validation Loss: 105.0444\n",
      "Epoch 19/150, Train Loss: 102.6164, Validation Loss: 123.2914\n",
      "patience_counter : 1\n",
      "Epoch 20/150, Train Loss: 109.9206, Validation Loss: 142.1766\n",
      "patience_counter : 2\n",
      "Epoch 21/150, Train Loss: 102.5679, Validation Loss: 102.9310\n",
      "Epoch 22/150, Train Loss: 102.2715, Validation Loss: 108.5200\n",
      "patience_counter : 1\n",
      "Epoch 23/150, Train Loss: 104.7334, Validation Loss: 106.3899\n",
      "patience_counter : 2\n",
      "Epoch 24/150, Train Loss: 101.1576, Validation Loss: 114.7811\n",
      "patience_counter : 3\n",
      "Early stopping triggered.\n",
      "‚è±Ô∏è Training time for this model: 391.80 seconds\n",
      "\n",
      "üîÅ Training model 4/5 with seed 45\n",
      "Epoch 1/150, Train Loss: 166.9941, Validation Loss: 138.6523\n",
      "Epoch 2/150, Train Loss: 165.0007, Validation Loss: 139.5616\n",
      "patience_counter : 1\n",
      "Epoch 3/150, Train Loss: 161.6119, Validation Loss: 135.1891\n",
      "Epoch 4/150, Train Loss: 156.2173, Validation Loss: 129.8739\n",
      "Epoch 5/150, Train Loss: 148.7802, Validation Loss: 124.9687\n",
      "Epoch 6/150, Train Loss: 140.8759, Validation Loss: 118.8830\n",
      "Epoch 7/150, Train Loss: 133.5395, Validation Loss: 114.6577\n",
      "Epoch 8/150, Train Loss: 125.1059, Validation Loss: 107.6728\n",
      "Epoch 9/150, Train Loss: 124.5000, Validation Loss: 100.0239\n",
      "Epoch 10/150, Train Loss: 118.4211, Validation Loss: 102.7433\n",
      "patience_counter : 1\n",
      "Epoch 11/150, Train Loss: 116.0981, Validation Loss: 116.4143\n",
      "patience_counter : 2\n",
      "Epoch 12/150, Train Loss: 115.9178, Validation Loss: 117.5489\n",
      "patience_counter : 3\n",
      "Early stopping triggered.\n",
      "‚è±Ô∏è Training time for this model: 179.22 seconds\n",
      "\n",
      "üîÅ Training model 5/5 with seed 46\n",
      "Epoch 1/150, Train Loss: 162.4918, Validation Loss: 158.8812\n",
      "Epoch 2/150, Train Loss: 160.4627, Validation Loss: 158.5474\n",
      "Epoch 3/150, Train Loss: 158.3760, Validation Loss: 152.1300\n",
      "Epoch 4/150, Train Loss: 153.9635, Validation Loss: 144.9269\n",
      "Epoch 5/150, Train Loss: 146.6398, Validation Loss: 137.1917\n",
      "Epoch 6/150, Train Loss: 138.4696, Validation Loss: 133.6026\n",
      "Epoch 7/150, Train Loss: 130.6337, Validation Loss: 128.3247\n",
      "Epoch 8/150, Train Loss: 122.2312, Validation Loss: 115.0314\n",
      "Epoch 9/150, Train Loss: 117.8621, Validation Loss: 116.1722\n",
      "patience_counter : 1\n",
      "Epoch 10/150, Train Loss: 117.5582, Validation Loss: 105.0078\n",
      "Epoch 11/150, Train Loss: 109.6058, Validation Loss: 101.7482\n",
      "Epoch 12/150, Train Loss: 111.8852, Validation Loss: 130.5010\n",
      "patience_counter : 1\n",
      "Epoch 13/150, Train Loss: 109.2777, Validation Loss: 103.2554\n",
      "patience_counter : 2\n",
      "Epoch 14/150, Train Loss: 104.6707, Validation Loss: 128.1159\n",
      "patience_counter : 3\n",
      "Early stopping triggered.\n",
      "‚è±Ô∏è Training time for this model: 109.39 seconds\n"
     ]
    }
   ],
   "source": [
    "##########################################\n",
    "# Train ensemble baseline models\n",
    "##########################################\n",
    "\n",
    "base_models_list = train_base_model(num_models=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7dfa13ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 | MAE: 97.321, RMSE: 142.713, R2: 0.671\n",
      "Model 2 | MAE: 96.105, RMSE: 141.306, R2: 0.677\n",
      "Model 3 | MAE: 101.242, RMSE: 143.305, R2: 0.668\n",
      "Model 4 | MAE: 120.492, RMSE: 154.623, R2: 0.613\n",
      "Model 5 | MAE: 119.472, RMSE: 161.688, R2: 0.577\n"
     ]
    }
   ],
   "source": [
    "#####################################################################\n",
    "# Evaluate the individual models for CNN baseline model\n",
    "#####################################################################\n",
    "\n",
    "ind_metric = evaluate_individual_models(ensemble_models=base_models_list,seed=42, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6ecc710",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************CNN Baseline Model*********************\n",
      "\n",
      "Evaluation results:\n",
      "MAE: 94.7015 \n",
      "RMSE: 141.2704 \n",
      "R¬≤: 0.6773\n",
      "********************************************************\n"
     ]
    }
   ],
   "source": [
    "#####################################################################\n",
    "# Display the metrics for Baseline CNN model \n",
    "#####################################################################\n",
    "\n",
    "Base_preds_list, base_std_list, base_targets_list = evaluate_models(\n",
    "    ensemble_models=base_models_list, seed=42, device='cpu'\n",
    ")\n",
    "\n",
    "base_mae = mean_absolute_error(base_targets_list, Base_preds_list)\n",
    "base_rmse = np.sqrt(mean_squared_error(base_targets_list, Base_preds_list))\n",
    "base_r2 = r2_score(base_targets_list, Base_preds_list)\n",
    "base_avg_uncertainty = base_std_list.mean()\n",
    "print(f\"*****************CNN Baseline Model*********************\")\n",
    "print(f\"\\nEvaluation results:\")\n",
    "print(f\"MAE: {base_mae:.4f} \\nRMSE: {base_rmse:.4f} \\nR¬≤: {base_r2:.4f}\")\n",
    "print(f\"********************************************************\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
