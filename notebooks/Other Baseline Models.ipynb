{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ea06fe4",
   "metadata": {},
   "source": [
    "# Other Non- causal Basline Models for comparison with our CAPRI-CT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6806e496",
   "metadata": {},
   "source": [
    "The non-causal baseline models is used as a reference point to compare against the causal-aware Capri-CT model. Unlike Capri-CT, which integrates causal reasoning to understand how interventions affect outcomes, the baseline model relies solely on correlational patterns in the data without explicitly modeling causal relationships.\n",
    "\n",
    "These baseline models typically consists of a ResNet model , SqueezeNet model and Densenet model(Unused for comparison). It predicts outcomes like Signal-to-Noise Ratio (SNR) based on observed features, without accounting for causal interventions.\n",
    "\n",
    "While effective at capturing associations, the non-causal baseline lacks robustness to changes caused by interventions or shifts in the data distribution. Therefore, it provides a meaningful benchmark to demonstrate the advantages of causal-aware models like Capri-CT in terms of interpretability, generalization, and handling of counterfactual scenarios.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53fc2d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################################\n",
    "# Importing the required libraries for other Baseline Non - Causal Models\n",
    "######################################################################################\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from pathlib import Path\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Subset\n",
    "from sklearn.metrics import mean_absolute_error,mean_squared_error, r2_score\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "from torch.optim import Adam, lr_scheduler\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torchvision.models import densenet121, DenseNet121_Weights\n",
    "from torchvision.models import squeezenet1_1, SqueezeNet1_1_Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e3cecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "##########################################################################################\n",
    "# Below is the Class CTDataset \n",
    "# Combining the CT image with the metadata using Dataset package\n",
    "# for SNR prediction\n",
    "##########################################################################################\n",
    "\n",
    "class CTDataset(Dataset):\n",
    "    \"\"\"\n",
    "    PyTorch Dataset for loading CT scan images and associated metadata.\n",
    "\n",
    "    Args:\n",
    "        metadata_csv (str or Path): Path to the CSV file containing metadata.\n",
    "        img_folder_path (str or Path): Directory containing CT scan image files.\n",
    "        transform (callable, optional): Transformations to apply to the images.\n",
    "\n",
    "    Attributes:\n",
    "        img_data (pd.DataFrame): DataFrame containing the metadata.\n",
    "        img_folder (Path): Path to the image folder.\n",
    "        transform (callable or None): Optional transform to apply to images.\n",
    "\n",
    "    Methods:\n",
    "        __getitem__(idx): Returns a single data sample consisting of:\n",
    "            - transformed image tensor (grayscale),\n",
    "            - one-hot encoded agent vector (tensor),\n",
    "            - voltage (tensor),\n",
    "            - time (tensor),\n",
    "            - SNR (tensor).\n",
    "        __len__(): Returns the total number of samples.\n",
    "    \"\"\"\n",
    "    def __init__(self, metadata_csv, img_folder_path, transform=None):\n",
    "        self.img_data = pd.read_csv(metadata_csv)\n",
    "        self.img_folder = img_folder_path\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.img_data.iloc[idx]\n",
    "        img = Image.open(os.path.join(self.img_folder, row['Filename'])).convert('L')\n",
    "        if self.transform:\n",
    "            image = self.transform(img)\n",
    "\n",
    "        agent_dict = {'Iodine': 0, 'BiNPs 50nm': 1, 'BiNPs 100nm': 2}\n",
    "        agent_vector = torch.zeros(len(agent_dict))\n",
    "        agent_vector[agent_dict[row['Classification']]] = 1\n",
    "\n",
    "        voltage = torch.tensor([row['Voltage']], dtype=torch.float32)\n",
    "        time = torch.tensor([row['Time']], dtype=torch.float32)\n",
    "        snr = torch.tensor([row['SNR']], dtype=torch.float32)\n",
    "\n",
    "        return image, agent_vector, voltage, time, snr\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44a8333",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################################################\n",
    "# get_data_loaders function:\n",
    "# Loads a CT dataset with images and metadata.\n",
    "# Splits the dataset into training and validation sets.\n",
    "# Applies image transformations.\n",
    "############################################################################################\n",
    "\n",
    "def get_data_loaders(seed, test_ind=False, model_name='sample'):\n",
    "    \"\"\"\n",
    "    Returns PyTorch DataLoaders for training and validation splits of the CT dataset.\n",
    "\n",
    "    Args:\n",
    "        seed (int): Random seed for reproducibility of dataset splits.\n",
    "        test_ind (bool): If True, returns a small subset of the dataset for testing/debugging.\n",
    "        model_name (str): Specifies model type ('resnet', 'squeezenet', 'densenet', or 'sample') \n",
    "                          to adjust input image resolution accordingly.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[DataLoader, DataLoader]: DataLoaders for training and validation sets.\n",
    "    \"\"\"\n",
    "    torch.manual_seed(seed)\n",
    "    generator = torch.Generator().manual_seed(seed)\n",
    "\n",
    "    if model_name=='resnet':\n",
    "        transform = transforms.Compose([\n",
    "        transforms.Resize((9, 9)),  \n",
    "        transforms.ToTensor()\n",
    "        ])\n",
    "    elif model_name =='squeezenet' or model_name == 'densenet':\n",
    "        transform = transforms.Compose([\n",
    "        transforms.Resize((128, 128)),  \n",
    "        transforms.ToTensor()\n",
    "        ])\n",
    "    else:\n",
    "        transform = transforms.Compose([\n",
    "        transforms.Resize((9, 9)),  \n",
    "        transforms.ToTensor()\n",
    "        ])\n",
    "    \n",
    "\n",
    "    base_path = Path(\"../dataset\")\n",
    "    \n",
    "    \n",
    "    dataset = CTDataset(\n",
    "        metadata_csv= base_path / \"final_dataset.csv\",\n",
    "        img_folder_path= base_path / \"img\" ,\n",
    "        transform=transform\n",
    "    )\n",
    "\n",
    "    if test_ind:\n",
    "        tiny_subset = torch.utils.data.Subset(dataset, indices=list(range(20)))\n",
    "        train_set, val_set = torch.utils.data.random_split(tiny_subset, [16, 4])\n",
    "        train_loader = DataLoader(train_set, batch_size=2, shuffle=True)\n",
    "        val_loader = DataLoader(val_set, batch_size=2)\n",
    "\n",
    "    else:\n",
    "        # Split\n",
    "        train_indices, val_indices = train_test_split(list(range(len(dataset))), test_size=0.2, random_state=seed)\n",
    "        train_subset = Subset(dataset, train_indices)\n",
    "        val_subset = Subset(dataset, val_indices)\n",
    "\n",
    "        # DataLoaders\n",
    "        train_loader = DataLoader(train_subset, batch_size=16, shuffle=True, generator=generator)\n",
    "        val_loader = DataLoader(val_subset, batch_size=16, shuffle=False)\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ce3196",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################\n",
    "# Setting the seed value for each training loop\n",
    "###############################################################\n",
    "\n",
    "def set_seed(seed):\n",
    "    \"\"\"\n",
    "    Sets the random seed across Python, NumPy, and PyTorch (CPU and GPU) for reproducibility.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    seed : int\n",
    "        The seed value to ensure deterministic behavior across runs.\n",
    "    \"\"\"\n",
    "    \n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc4d1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################################\n",
    "# Below is our Simple Resnet Baseline Non - Causal Model\n",
    "#################################################################################\n",
    "\n",
    "class SimpleResidualBlock1(nn.Module):\n",
    "    \"\"\"\n",
    "    A basic residual block with two convolutional layers and an optional downsampling path.\n",
    "\n",
    "    Args:\n",
    "        in_channels (int): Number of input channels.\n",
    "        out_channels (int): Number of output channels.\n",
    "        downsample (bool): Whether to downsample the input (by stride=2) to match output size.\n",
    "\n",
    "    Structure:\n",
    "        - Conv → BN → ReLU → Conv → BN\n",
    "        - Optional downsampling for residual path\n",
    "        - Residual connection added to output\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, downsample=False):\n",
    "        super().__init__()\n",
    "        stride = 2 if downsample else 1\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, 3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, 3, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.downsample = None\n",
    "        if downsample or in_channels != out_channels:\n",
    "            self.downsample = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, 1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = F.relu(self.bn1(self.conv1(x)), inplace=True)\n",
    "        out = self.bn2(self.conv2(out))\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(identity)\n",
    "\n",
    "        out += identity\n",
    "        return F.relu(out, inplace=True)\n",
    "\n",
    "class CTResNetModel(nn.Module):\n",
    "    \"\"\"\n",
    "    A ResNet-based model for CT image analysis with metadata fusion for SNR prediction.\n",
    "\n",
    "    Args:\n",
    "        image_channels (int): Number of input image channels (default is 1 for grayscale CT).\n",
    "        meta_dim (int): Dimension of the metadata vector (default is 5).\n",
    "\n",
    "    Architecture:\n",
    "        - Convolutional stem followed by stacked residual blocks\n",
    "        - Adaptive pooling to flatten image features\n",
    "        - Metadata (e.g., voltage, time, agent) passed through a feedforward network\n",
    "        - Image and metadata features are concatenated and passed through fully connected layers\n",
    "        - Outputs a single SNR prediction (regression)\n",
    "\n",
    "    Forward Inputs:\n",
    "        - image (Tensor): CT image tensor of shape (B, C, H, W)\n",
    "        - agent_vector (Tensor): Encoded vector for contrast agent\n",
    "        - voltage (Tensor): Voltage metadata (B, 1)\n",
    "        - time (Tensor): Time metadata (B, 1)\n",
    "\n",
    "    Returns:\n",
    "        - snr (Tensor): Predicted SNR value for each input image (B, 1)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, image_channels=1, meta_dim=5):\n",
    "        super().__init__()\n",
    "\n",
    "        self.stem_channels = 64\n",
    "\n",
    "        self.stem = nn.Sequential(\n",
    "            nn.Conv2d(image_channels, self.stem_channels, 3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(self.stem_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        self.blocks = nn.Sequential(\n",
    "            SimpleResidualBlock1(self.stem_channels, 64, downsample=False),   # 9x9 -> 9x9\n",
    "            SimpleResidualBlock1(64, 128, downsample=True),                   # 9x9 -> 5x5\n",
    "            SimpleResidualBlock1(128, 128, downsample=False),                 # 5x5 -> 5x5\n",
    "            SimpleResidualBlock1(128, 256, downsample=True),                  # 5x5 -> 3x3\n",
    "            SimpleResidualBlock1(256, 256, downsample=False),                 # 3x3 -> 3x3\n",
    "        )\n",
    "\n",
    "        self.adaptive_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.flat_dim = 256\n",
    "\n",
    "        # Meta network stays the same but outputs 32 dims\n",
    "        self.meta_net = nn.Sequential(\n",
    "            nn.Linear(meta_dim, 64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        # Fully connected layers now take fused feature + meta together\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(self.flat_dim + 32, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.2)\n",
    "        )\n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear(256, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.2)\n",
    "        )\n",
    "\n",
    "        self.head_snr = nn.Linear(128, 1)\n",
    "\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, (nn.Conv2d, nn.Linear)):\n",
    "                nn.init.kaiming_normal_(m.weight, nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, image, agent_vector, voltage, time):\n",
    "        x = self.stem(image)\n",
    "        x = self.blocks(x)\n",
    "        x = self.adaptive_pool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        meta = torch.cat([voltage, time, agent_vector], dim=1)\n",
    "        meta = self.meta_net(meta)\n",
    "\n",
    "        fused = torch.cat([x, meta], dim=1)\n",
    "        fused = self.fc1(fused)\n",
    "        fused = self.fc2(fused)\n",
    "\n",
    "        snr = self.head_snr(fused)\n",
    "\n",
    "        return snr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941ef0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################################\n",
    "# Below is our SqueezeNet Baseline Non - Causal Model\n",
    "#################################################################################\n",
    "\n",
    "class SqueezeNetSNR(nn.Module):\n",
    "    \"\"\"\n",
    "    A lightweight SqueezeNet-based model for predicting Signal-to-Noise Ratio (SNR) from CT images and metadata.\n",
    "\n",
    "    Args:\n",
    "        input_dim (int): Dimension of metadata input (default=5), typically from agent_vector, voltage, and time.\n",
    "\n",
    "    Architecture:\n",
    "        - Uses a pretrained SqueezeNet (v1.1) backbone with modified first layer for grayscale images.\n",
    "        - Extracted CNN features are combined with metadata.\n",
    "        - Fused features are passed through fully connected layers to predict a single SNR value.\n",
    "\n",
    "    Forward Inputs:\n",
    "        - image (Tensor): Grayscale CT image tensor of shape (B, 1, H, W)\n",
    "        - agent_vector (Tensor): One-hot or embedded contrast agent vector (B, *)\n",
    "        - voltage (Tensor): Scalar voltage input (B, 1)\n",
    "        - time (Tensor): Scalar acquisition time (B, 1)\n",
    "\n",
    "    Returns:\n",
    "        - snr_out (Tensor): Predicted SNR values for each image in the batch (B, 1)\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim=5):  # input_dim = len(agent_vector + voltage + time)\n",
    "        super(SqueezeNetSNR, self).__init__()\n",
    "\n",
    "        weights = SqueezeNet1_1_Weights.DEFAULT  \n",
    "        self.backbone = squeezenet1_1(weights=weights)\n",
    "\n",
    "        # Modify the first conv layer to accept 1-channel (grayscale) input\n",
    "        self.backbone.features[0] = nn.Conv2d(1, 64, kernel_size=3, stride=2)\n",
    "\n",
    "        self.backbone.classifier = nn.Identity()\n",
    "\n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "\n",
    "        # Combine CNN features with metadata (5 inputs)\n",
    "        self.fc1 = nn.Linear(512 + input_dim, 256)\n",
    "        self.fc2 = nn.Linear(256, 64)\n",
    "        self.fc_out = nn.Linear(64, 1) \n",
    "\n",
    "    def forward(self, image, agent_vector, voltage, time):\n",
    "        # Feature extraction\n",
    "        x = self.backbone.features(image)            # (B, 512, H, W)\n",
    "        x = self.global_avg_pool(x)                  # (B, 512, 1, 1)\n",
    "        x = torch.flatten(x, 1)                      # (B, 512)\n",
    "\n",
    "        # Metadata\n",
    "        meta = torch.cat([voltage, time, agent_vector], dim=1)  # (B, 5)\n",
    "\n",
    "        # Fully connected layers\n",
    "        x = torch.cat([x, meta], dim=1)              # (B, 512 + 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        snr_out = self.fc_out(x)\n",
    "\n",
    "        return snr_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950ed787",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################\n",
    "# Train one epoch\n",
    "##############################################################\n",
    "def train_one_epoch(model, dataloader, optimizer, criterion, device):\n",
    "    \"\"\"\n",
    "    Trains the model for one epoch.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The neural network model.\n",
    "        dataloader (DataLoader): DataLoader for training data.\n",
    "        optimizer (torch.optim.Optimizer): Optimizer used for training.\n",
    "        criterion (nn.Module): Loss function.\n",
    "        device (torch.device): Device to run computations on (CPU or CUDA).\n",
    "\n",
    "    Returns:\n",
    "        float: Average training loss for the epoch.\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, agent_vector, voltage, time, snr_targets in dataloader:\n",
    "        images = images.to(device)\n",
    "        voltage = voltage.to(device)\n",
    "        time = time.to(device)\n",
    "        agent_vector = agent_vector.to(device)\n",
    "        snr_targets = snr_targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        snr_preds = model(images, agent_vector, voltage, time)\n",
    "        loss = criterion(snr_preds.squeeze(), snr_targets.squeeze())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / len(dataloader.dataset)\n",
    "    return epoch_loss\n",
    "\n",
    "############################################################################\n",
    "# Evaluates the model on validation data for one epoch.\n",
    "############################################################################\n",
    "def validate_one_epoch(model, dataloader, criterion, device):\n",
    "    \"\"\"\n",
    "    Evaluates the model on validation data for one epoch.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The neural network model.\n",
    "        dataloader (DataLoader): DataLoader for validation data.\n",
    "        criterion (nn.Module): Loss function.\n",
    "        device (torch.device): Device to run computations on (CPU or CUDA).\n",
    "\n",
    "    Returns:\n",
    "        float: Average validation loss for the epoch.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for images, agent_vector, voltage, time, snr_targets in dataloader:\n",
    "            images = images.to(device)\n",
    "            voltage = voltage.to(device)\n",
    "            time = time.to(device)\n",
    "            agent_vector = agent_vector.to(device)\n",
    "            snr_targets = snr_targets.to(device)\n",
    "            snr_preds = model(images, agent_vector, voltage, time)\n",
    "            loss = criterion(snr_preds.squeeze(), snr_targets.squeeze())\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / len(dataloader.dataset)\n",
    "    return epoch_loss\n",
    "\n",
    "############################################################################################\n",
    "# Trains the model over multiple epochs with early stopping and learning rate scheduling\n",
    "############################################################################################\n",
    "def train_model_new(model, train_loader, val_loader, device, epochs=100, lr=1e-4, patience=7):\n",
    "    \"\"\"\n",
    "    Trains the model over multiple epochs with early stopping and learning rate scheduling.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): The neural network model.\n",
    "        train_loader (DataLoader): DataLoader for training data.\n",
    "        val_loader (DataLoader): DataLoader for validation data.\n",
    "        device (torch.device): Device to run computations on (CPU or CUDA).\n",
    "        epochs (int): Maximum number of training epochs.\n",
    "        lr (float): Initial learning rate.\n",
    "        patience (int): Number of epochs to wait for improvement before early stopping.\n",
    "\n",
    "    Saves:\n",
    "        best_model.pth: The model weights with the lowest validation loss.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    model.to(device)\n",
    "    optimizer = Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.MSELoss()\n",
    "    scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5)\n",
    "\n",
    "    best_val_loss = float('inf')\n",
    "    epochs_no_improve = 0\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        train_loss = train_one_epoch(model, train_loader, optimizer, criterion, device)\n",
    "        val_loss = validate_one_epoch(model, val_loader, criterion, device)\n",
    "\n",
    "        print(f\"Epoch {epoch}/{epochs} — Train Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}\")\n",
    "        scheduler.step(val_loss)\n",
    "        print(f\"Learning rate: {scheduler.optimizer.param_groups[0]['lr']:.6f}\")\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            epochs_no_improve = 0\n",
    "            torch.save(model.state_dict(), \"best_model.pth\")\n",
    "            print(\"Best model saved.\")\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            print(f\"No improvement for {epochs_no_improve} epoch(s).\")\n",
    "\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(f\"Early stopping triggered after {epoch} epochs.\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5497f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################################################################\n",
    "# Below is our DenseNet Baseline Non - Causal Model\n",
    "#################################################################################\n",
    "\n",
    "class DenseNetSNR(nn.Module):\n",
    "    \"\"\"\n",
    "    DenseNet-based neural network for predicting SNR from grayscale CT images and metadata.\n",
    "\n",
    "    Combines image features extracted using a pre-trained DenseNet121 (adapted for 1-channel input)\n",
    "    with additional input metadata (contrast agent vector, voltage, and time).\n",
    "\n",
    "    Args:\n",
    "        input_dim (int): Dimensionality of metadata input (default is 5, combining voltage, time, and agent vector).\n",
    "\n",
    "    Forward Inputs:\n",
    "        image (Tensor): Grayscale CT image tensor of shape (B, 1, H, W).\n",
    "        agent_vector (Tensor): Encoded contrast agent metadata of shape (B, n).\n",
    "        voltage (Tensor): Voltage values of shape (B, 1).\n",
    "        time (Tensor): Exposure time values of shape (B, 1).\n",
    "\n",
    "    Returns:\n",
    "        Tensor: Predicted SNR values of shape (B, 1).\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, input_dim=5):  # input_dim = len(agent_vector + voltage + time)\n",
    "        super(DenseNetSNR, self).__init__()\n",
    "\n",
    "        # Load pre-trained DenseNet121\n",
    "        weights = DenseNet121_Weights.DEFAULT\n",
    "        self.backbone = densenet121(weights=weights)\n",
    "\n",
    "        # Modify input layer if grayscale\n",
    "        self.backbone.features.conv0 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "\n",
    "        self.backbone.classifier = nn.Identity()\n",
    "        self.global_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "\n",
    "        # Combine CNN features with metadata\n",
    "        self.fc1 = nn.Linear(1024 + input_dim, 256)\n",
    "        self.fc2 = nn.Linear(256, 64)\n",
    "        self.fc_out = nn.Linear(64, 1) \n",
    "\n",
    "    def forward(self, image, agent_vector, voltage, time):\n",
    "        x = self.backbone.features(image)         # (B, 1024, H, W)\n",
    "        x = self.global_pool(x)                   # (B, 1024, 1, 1)\n",
    "        x = torch.flatten(x, 1)                   # (B, 1024)\n",
    "\n",
    "        # Metadata (voltage, time, agent_vector)\n",
    "        meta = torch.cat([voltage, time, agent_vector], dim=1)  # (B, input_dim)\n",
    "        x = torch.cat([x, meta], dim=1)                         # (B, 1029)\n",
    "\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        snr_out = self.fc_out(x)\n",
    "\n",
    "        return snr_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11318c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################################\n",
    "# Trains an ensemble of deep learning models on CT image data for SNR prediction.\n",
    "##################################################################################################\n",
    "\n",
    "def train_deep_ensemble(num_models=5, base_seed=42, pretrained=True, model_name='default'):\n",
    "    \"\"\"\n",
    "    Trains an ensemble of deep learning models on CT image data for SNR prediction.\n",
    "\n",
    "    Each model in the ensemble is trained with a different random seed to encourage diversity.\n",
    "\n",
    "    Args:\n",
    "        num_models (int): Number of models to train in the ensemble. Default is 5.\n",
    "        base_seed (int): Base seed for reproducibility. Each model will use (base_seed + i). Default is 42.\n",
    "        pretrained (bool): Whether to use pre-trained weights for backbone networks. Currently not used. Default is True.\n",
    "        model_name (str): Model architecture to use — 'resnet', 'squeezenet', or 'densenet'. Default is 'default'.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of trained model instances forming the ensemble.\n",
    "    \"\"\"\n",
    "    ensemble_models_list = []\n",
    "    \n",
    "    for i in range(num_models):\n",
    "        seed = base_seed + i\n",
    "        print(f\"\\n🔁 Training model {i+1}/{num_models} with seed {seed}\")\n",
    "        set_seed(seed)\n",
    "\n",
    "        if model_name=='resnet':\n",
    "            model = CTResNetModel()\n",
    "            lr_value = 1e-4\n",
    "        elif model_name == 'squeezenet':\n",
    "            model = SqueezeNetSNR(input_dim=5)\n",
    "            lr_value = 1e-3\n",
    "        elif model_name == 'densenet':\n",
    "            model = DenseNetSNR(input_dim=5)\n",
    "            lr_value = 1e-3\n",
    "            \n",
    "        train_loader, val_loader = get_data_loaders(seed=seed, test_ind=False, model_name=model_name)\n",
    "        train_model_new(model, train_loader, val_loader,device='cpu',lr=lr_value)\n",
    "        ensemble_models_list.append(model)\n",
    "\n",
    "    return ensemble_models_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b5c46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################\n",
    "# Evaluates a trained model on a given dataloader\n",
    "# computes regression metrics for SNR prediction.\n",
    "##############################################################\n",
    "def evaluate_model(model, dataloader, device):\n",
    "    \"\"\"\n",
    "    Evaluates a trained model on a given dataloader and computes regression metrics for SNR prediction.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): Trained model to be evaluated.\n",
    "        dataloader (DataLoader): DataLoader containing the test/validation dataset.\n",
    "        device (torch.device or str): Device to run evaluation on (e.g., 'cpu' or 'cuda').\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary containing Mean Absolute Error (MAE), Root Mean Squared Error (RMSE), and R² score for SNR prediction.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    all_snr_true = []\n",
    "    all_snr_pred = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            images = batch[0].to(device)\n",
    "            agent_vector = batch[1].to(device)\n",
    "            voltage = batch[2].to(device)\n",
    "            time = batch[3].to(device)\n",
    "            y_true_snr = batch[4].to(device)\n",
    "\n",
    "            y_pred_snr = model(images, agent_vector, voltage, time)\n",
    "\n",
    "            all_snr_true.append(y_true_snr.cpu().numpy())\n",
    "            all_snr_pred.append(y_pred_snr.cpu().numpy())\n",
    "\n",
    "    # Convert lists to numpy arrays\n",
    "    all_snr_true = np.concatenate(all_snr_true).flatten()\n",
    "    all_snr_pred = np.concatenate(all_snr_pred).flatten()\n",
    "\n",
    "    # Calculate metrics for SNR\n",
    "    snr_mae = mean_absolute_error(all_snr_true, all_snr_pred)\n",
    "    snr_rmse = np.sqrt(mean_squared_error(all_snr_true, all_snr_pred))\n",
    "    snr_r2 = r2_score(all_snr_true, all_snr_pred)\n",
    "\n",
    "    print(f\"SNR -> MAE: {snr_mae:.4f}, RMSE: {snr_rmse:.4f}, R2: {snr_r2:.4f}\")\n",
    "\n",
    "    return {\n",
    "        'snr_mae': snr_mae,\n",
    "        'snr_rmse': snr_rmse,\n",
    "        'snr_r2': snr_r2\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d95fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################\n",
    "# Evaluates an ensemble of trained models on a validation set\n",
    "# estimates prediction uncertainty\n",
    "################################################################\n",
    "\n",
    "def evaluate_models(ensemble_models, seed, device='cpu'):\n",
    "    \"\"\"\n",
    "    Evaluates an ensemble of trained models on a validation set and estimates prediction uncertainty.\n",
    "\n",
    "    Args:\n",
    "        ensemble_models (list): List of trained PyTorch models.\n",
    "        seed (int): Random seed used for reproducibility in data loading.\n",
    "        device (str): Device to run the evaluation on ('cpu' or 'cuda').\n",
    "\n",
    "    Returns:\n",
    "        tuple:\n",
    "            - preds_mean (np.ndarray): Mean SNR predictions across ensemble models.\n",
    "            - preds_std (np.ndarray): Standard deviation of SNR predictions (uncertainty estimate).\n",
    "            - targets (np.ndarray): Ground truth SNR values.\n",
    "    \"\"\"\n",
    "    train_loader, val_loader = get_data_loaders(seed)\n",
    "\n",
    "    preds_mean, preds_std, targets = [], [], []\n",
    "\n",
    "    for image, agent_vector, voltage, time, snr in val_loader:\n",
    "        image = image.to(device)\n",
    "        agent_vector = agent_vector.to(device)\n",
    "        voltage = voltage.to(device)\n",
    "        time = time.to(device)\n",
    "        snr = snr.to(device)\n",
    "\n",
    "        batch_preds = []\n",
    "        with torch.no_grad():\n",
    "            for model in ensemble_models:\n",
    "                model.eval()\n",
    "                model.to(device)\n",
    "                output = model(image, agent_vector, voltage, time)\n",
    "                batch_preds.append(output.cpu())\n",
    "\n",
    "        batch_preds = torch.stack(batch_preds)  # [num_models, B, 1]\n",
    "        mean_pred = batch_preds.mean(dim=0).squeeze().numpy()     # [B, 1]\n",
    "        std_pred = batch_preds.std(dim=0).squeeze().numpy()       # [B, 1]\n",
    "\n",
    "        preds_mean.extend(mean_pred)\n",
    "        preds_std.extend(std_pred)\n",
    "        targets.extend(snr.cpu().numpy())\n",
    "\n",
    "    preds_mean = np.array(preds_mean)\n",
    "    preds_std = np.array(preds_std)\n",
    "    targets = np.array(targets)\n",
    "\n",
    "    \n",
    "\n",
    "    return preds_mean, preds_std, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0677ff69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔁 Training model 1/5 with seed 42\n",
      "Epoch 1/100 — Train Loss: 62033.3712, Validation Loss: 71287.0727\n",
      "Learning rate: 0.000100\n",
      "Best model saved.\n",
      "Epoch 2/100 — Train Loss: 61720.8282, Validation Loss: 71054.2485\n",
      "Learning rate: 0.000100\n",
      "Best model saved.\n",
      "Epoch 3/100 — Train Loss: 61516.8896, Validation Loss: 70771.4437\n",
      "Learning rate: 0.000100\n",
      "Best model saved.\n",
      "Epoch 4/100 — Train Loss: 61291.5965, Validation Loss: 70483.0904\n",
      "Learning rate: 0.000100\n",
      "Best model saved.\n",
      "Epoch 5/100 — Train Loss: 61025.5429, Validation Loss: 69884.3221\n",
      "Learning rate: 0.000100\n",
      "Best model saved.\n",
      "Epoch 6/100 — Train Loss: 60557.6296, Validation Loss: 70370.6703\n",
      "Learning rate: 0.000100\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch 7/100 — Train Loss: 59971.5350, Validation Loss: 69693.2765\n",
      "Learning rate: 0.000100\n",
      "Best model saved.\n",
      "Epoch 8/100 — Train Loss: 59155.7133, Validation Loss: 63758.9907\n",
      "Learning rate: 0.000100\n",
      "Best model saved.\n",
      "Epoch 9/100 — Train Loss: 58138.4520, Validation Loss: 67582.0668\n",
      "Learning rate: 0.000100\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch 10/100 — Train Loss: 57320.4657, Validation Loss: 71614.3996\n",
      "Learning rate: 0.000100\n",
      "No improvement for 2 epoch(s).\n",
      "Epoch 11/100 — Train Loss: 56465.7430, Validation Loss: 68998.2464\n",
      "Learning rate: 0.000100\n",
      "No improvement for 3 epoch(s).\n",
      "Epoch 12/100 — Train Loss: 55273.3380, Validation Loss: 65922.8606\n",
      "Learning rate: 0.000100\n",
      "No improvement for 4 epoch(s).\n",
      "Epoch 13/100 — Train Loss: 54519.4325, Validation Loss: 59721.4500\n",
      "Learning rate: 0.000100\n",
      "Best model saved.\n",
      "Epoch 14/100 — Train Loss: 53651.2348, Validation Loss: 59680.4474\n",
      "Learning rate: 0.000100\n",
      "Best model saved.\n",
      "Epoch 15/100 — Train Loss: 53045.5712, Validation Loss: 63624.7626\n",
      "Learning rate: 0.000100\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch 16/100 — Train Loss: 52176.0572, Validation Loss: 61462.8633\n",
      "Learning rate: 0.000100\n",
      "No improvement for 2 epoch(s).\n",
      "Epoch 17/100 — Train Loss: 51485.4950, Validation Loss: 60772.6307\n",
      "Learning rate: 0.000100\n",
      "No improvement for 3 epoch(s).\n",
      "Epoch 18/100 — Train Loss: 50767.5927, Validation Loss: 63011.8366\n",
      "Learning rate: 0.000100\n",
      "No improvement for 4 epoch(s).\n",
      "Epoch 19/100 — Train Loss: 49779.0214, Validation Loss: 57712.2490\n",
      "Learning rate: 0.000100\n",
      "Best model saved.\n",
      "Epoch 20/100 — Train Loss: 48947.8967, Validation Loss: 53578.1681\n",
      "Learning rate: 0.000100\n",
      "Best model saved.\n",
      "Epoch 21/100 — Train Loss: 48097.1590, Validation Loss: 51837.3927\n",
      "Learning rate: 0.000100\n",
      "Best model saved.\n",
      "Epoch 22/100 — Train Loss: 47433.0972, Validation Loss: 55024.4988\n",
      "Learning rate: 0.000100\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch 23/100 — Train Loss: 46565.7263, Validation Loss: 44686.8653\n",
      "Learning rate: 0.000100\n",
      "Best model saved.\n",
      "Epoch 24/100 — Train Loss: 45753.9685, Validation Loss: 49425.0390\n",
      "Learning rate: 0.000100\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch 25/100 — Train Loss: 45215.7299, Validation Loss: 56143.4052\n",
      "Learning rate: 0.000100\n",
      "No improvement for 2 epoch(s).\n",
      "Epoch 26/100 — Train Loss: 44273.8619, Validation Loss: 42861.8755\n",
      "Learning rate: 0.000100\n",
      "Best model saved.\n",
      "Epoch 27/100 — Train Loss: 43359.3305, Validation Loss: 51332.3914\n",
      "Learning rate: 0.000100\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch 28/100 — Train Loss: 42781.7478, Validation Loss: 69990.9494\n",
      "Learning rate: 0.000100\n",
      "No improvement for 2 epoch(s).\n",
      "Epoch 29/100 — Train Loss: 42501.3084, Validation Loss: 37506.7268\n",
      "Learning rate: 0.000100\n",
      "Best model saved.\n",
      "Epoch 30/100 — Train Loss: 40962.0029, Validation Loss: 48423.4193\n",
      "Learning rate: 0.000100\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch 31/100 — Train Loss: 40563.6769, Validation Loss: 47922.9444\n",
      "Learning rate: 0.000100\n",
      "No improvement for 2 epoch(s).\n",
      "Epoch 32/100 — Train Loss: 40177.1349, Validation Loss: 40015.3742\n",
      "Learning rate: 0.000100\n",
      "No improvement for 3 epoch(s).\n",
      "Epoch 33/100 — Train Loss: 39036.1604, Validation Loss: 37992.0296\n",
      "Learning rate: 0.000100\n",
      "No improvement for 4 epoch(s).\n",
      "Epoch 34/100 — Train Loss: 38862.9851, Validation Loss: 40631.1088\n",
      "Learning rate: 0.000100\n",
      "No improvement for 5 epoch(s).\n",
      "Epoch 35/100 — Train Loss: 37019.1586, Validation Loss: 38641.4252\n",
      "Learning rate: 0.000050\n",
      "No improvement for 6 epoch(s).\n",
      "Epoch 36/100 — Train Loss: 36827.1863, Validation Loss: 36893.6826\n",
      "Learning rate: 0.000050\n",
      "Best model saved.\n",
      "Epoch 37/100 — Train Loss: 36832.7821, Validation Loss: 49224.4621\n",
      "Learning rate: 0.000050\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch 38/100 — Train Loss: 36875.6841, Validation Loss: 43879.6529\n",
      "Learning rate: 0.000050\n",
      "No improvement for 2 epoch(s).\n",
      "Epoch 39/100 — Train Loss: 35517.0210, Validation Loss: 42661.2962\n",
      "Learning rate: 0.000050\n",
      "No improvement for 3 epoch(s).\n",
      "Epoch 40/100 — Train Loss: 35660.6211, Validation Loss: 38415.7620\n",
      "Learning rate: 0.000050\n",
      "No improvement for 4 epoch(s).\n",
      "Epoch 41/100 — Train Loss: 35048.4699, Validation Loss: 38770.3674\n",
      "Learning rate: 0.000050\n",
      "No improvement for 5 epoch(s).\n",
      "Epoch 42/100 — Train Loss: 34614.7784, Validation Loss: 30387.2612\n",
      "Learning rate: 0.000050\n",
      "Best model saved.\n",
      "Epoch 43/100 — Train Loss: 34035.4453, Validation Loss: 27891.0118\n",
      "Learning rate: 0.000050\n",
      "Best model saved.\n",
      "Epoch 44/100 — Train Loss: 34212.1846, Validation Loss: 29725.8115\n",
      "Learning rate: 0.000050\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch 45/100 — Train Loss: 33722.2418, Validation Loss: 30015.4566\n",
      "Learning rate: 0.000050\n",
      "No improvement for 2 epoch(s).\n",
      "Epoch 46/100 — Train Loss: 33378.3657, Validation Loss: 31895.9674\n",
      "Learning rate: 0.000050\n",
      "No improvement for 3 epoch(s).\n",
      "Epoch 47/100 — Train Loss: 33598.5167, Validation Loss: 40544.1400\n",
      "Learning rate: 0.000050\n",
      "No improvement for 4 epoch(s).\n",
      "Epoch 48/100 — Train Loss: 32997.5559, Validation Loss: 34545.8350\n",
      "Learning rate: 0.000050\n",
      "No improvement for 5 epoch(s).\n",
      "Epoch 49/100 — Train Loss: 32799.5038, Validation Loss: 30828.0075\n",
      "Learning rate: 0.000025\n",
      "No improvement for 6 epoch(s).\n",
      "Epoch 50/100 — Train Loss: 32184.5744, Validation Loss: 32742.2456\n",
      "Learning rate: 0.000025\n",
      "No improvement for 7 epoch(s).\n",
      "Early stopping triggered after 50 epochs.\n",
      "\n",
      "🔁 Training model 2/5 with seed 43\n",
      "Epoch 1/100 — Train Loss: 64060.0568, Validation Loss: 63256.8178\n",
      "Learning rate: 0.000100\n",
      "Best model saved.\n",
      "Epoch 2/100 — Train Loss: 63808.6879, Validation Loss: 63033.9743\n",
      "Learning rate: 0.000100\n",
      "Best model saved.\n",
      "Epoch 3/100 — Train Loss: 63600.7864, Validation Loss: 62800.1531\n",
      "Learning rate: 0.000100\n",
      "Best model saved.\n",
      "Epoch 4/100 — Train Loss: 63377.2932, Validation Loss: 62753.2977\n",
      "Learning rate: 0.000100\n",
      "Best model saved.\n",
      "Epoch 5/100 — Train Loss: 63210.1239, Validation Loss: 62619.7022\n",
      "Learning rate: 0.000100\n",
      "Best model saved.\n",
      "Epoch 6/100 — Train Loss: 63017.7484, Validation Loss: 62360.8453\n",
      "Learning rate: 0.000100\n",
      "Best model saved.\n",
      "Epoch 7/100 — Train Loss: 62749.0565, Validation Loss: 62635.4023\n",
      "Learning rate: 0.000100\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch 8/100 — Train Loss: 62507.3736, Validation Loss: 62066.1546\n",
      "Learning rate: 0.000100\n",
      "Best model saved.\n",
      "Epoch 9/100 — Train Loss: 62058.4495, Validation Loss: 62200.7679\n",
      "Learning rate: 0.000100\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch 10/100 — Train Loss: 61387.8458, Validation Loss: 60172.1610\n",
      "Learning rate: 0.000100\n",
      "Best model saved.\n",
      "Epoch 11/100 — Train Loss: 60249.2162, Validation Loss: 54439.6089\n",
      "Learning rate: 0.000100\n",
      "Best model saved.\n",
      "Epoch 12/100 — Train Loss: 58964.6750, Validation Loss: 54836.3641\n",
      "Learning rate: 0.000100\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch 13/100 — Train Loss: 57960.7125, Validation Loss: 52847.7646\n",
      "Learning rate: 0.000100\n",
      "Best model saved.\n",
      "Epoch 14/100 — Train Loss: 56936.1325, Validation Loss: 57142.3908\n",
      "Learning rate: 0.000100\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch 15/100 — Train Loss: 56052.0189, Validation Loss: 58407.6080\n",
      "Learning rate: 0.000100\n",
      "No improvement for 2 epoch(s).\n",
      "Epoch 16/100 — Train Loss: 54977.8896, Validation Loss: 50963.0058\n",
      "Learning rate: 0.000100\n",
      "Best model saved.\n",
      "Epoch 17/100 — Train Loss: 53954.9803, Validation Loss: 47603.5872\n",
      "Learning rate: 0.000100\n",
      "Best model saved.\n",
      "Epoch 18/100 — Train Loss: 53093.1802, Validation Loss: 52854.5977\n",
      "Learning rate: 0.000100\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch 19/100 — Train Loss: 52326.1815, Validation Loss: 56157.5556\n",
      "Learning rate: 0.000100\n",
      "No improvement for 2 epoch(s).\n",
      "Epoch 20/100 — Train Loss: 51809.3979, Validation Loss: 52403.5013\n",
      "Learning rate: 0.000100\n",
      "No improvement for 3 epoch(s).\n",
      "Epoch 21/100 — Train Loss: 50701.9230, Validation Loss: 50842.0950\n",
      "Learning rate: 0.000100\n",
      "No improvement for 4 epoch(s).\n",
      "Epoch 22/100 — Train Loss: 49644.9680, Validation Loss: 47721.0472\n",
      "Learning rate: 0.000100\n",
      "No improvement for 5 epoch(s).\n",
      "Epoch 23/100 — Train Loss: 48969.3294, Validation Loss: 41191.6373\n",
      "Learning rate: 0.000100\n",
      "Best model saved.\n",
      "Epoch 24/100 — Train Loss: 47878.5567, Validation Loss: 60468.8128\n",
      "Learning rate: 0.000100\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch 25/100 — Train Loss: 46909.5238, Validation Loss: 42159.6297\n",
      "Learning rate: 0.000100\n",
      "No improvement for 2 epoch(s).\n",
      "Epoch 26/100 — Train Loss: 46144.3147, Validation Loss: 45057.6470\n",
      "Learning rate: 0.000100\n",
      "No improvement for 3 epoch(s).\n",
      "Epoch 27/100 — Train Loss: 45514.5675, Validation Loss: 43600.9292\n",
      "Learning rate: 0.000100\n",
      "No improvement for 4 epoch(s).\n",
      "Epoch 28/100 — Train Loss: 45009.5533, Validation Loss: 42804.7844\n",
      "Learning rate: 0.000100\n",
      "No improvement for 5 epoch(s).\n",
      "Epoch 29/100 — Train Loss: 43284.3088, Validation Loss: 57251.4739\n",
      "Learning rate: 0.000050\n",
      "No improvement for 6 epoch(s).\n",
      "Epoch 30/100 — Train Loss: 42507.1165, Validation Loss: 44305.2871\n",
      "Learning rate: 0.000050\n",
      "No improvement for 7 epoch(s).\n",
      "Early stopping triggered after 30 epochs.\n",
      "\n",
      "🔁 Training model 3/5 with seed 44\n",
      "Epoch 1/100 — Train Loss: 61068.1968, Validation Loss: 74875.2226\n",
      "Learning rate: 0.000100\n",
      "Best model saved.\n",
      "Epoch 2/100 — Train Loss: 60815.2074, Validation Loss: 74586.7405\n",
      "Learning rate: 0.000100\n",
      "Best model saved.\n",
      "Epoch 3/100 — Train Loss: 60601.3981, Validation Loss: 74680.3364\n",
      "Learning rate: 0.000100\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch 4/100 — Train Loss: 60390.7428, Validation Loss: 74138.5560\n",
      "Learning rate: 0.000100\n",
      "Best model saved.\n",
      "Epoch 5/100 — Train Loss: 60186.0767, Validation Loss: 73869.1135\n",
      "Learning rate: 0.000100\n",
      "Best model saved.\n",
      "Epoch 6/100 — Train Loss: 60021.2759, Validation Loss: 73931.7520\n",
      "Learning rate: 0.000100\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch 7/100 — Train Loss: 59828.4633, Validation Loss: 73593.0558\n",
      "Learning rate: 0.000100\n",
      "Best model saved.\n",
      "Epoch 8/100 — Train Loss: 59661.6979, Validation Loss: 72999.9008\n",
      "Learning rate: 0.000100\n",
      "Best model saved.\n",
      "Epoch 9/100 — Train Loss: 59543.8008, Validation Loss: 72011.0169\n",
      "Learning rate: 0.000100\n",
      "Best model saved.\n",
      "Epoch 10/100 — Train Loss: 59164.8727, Validation Loss: 73894.4136\n",
      "Learning rate: 0.000100\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch 11/100 — Train Loss: 58865.3455, Validation Loss: 71859.8209\n",
      "Learning rate: 0.000100\n",
      "Best model saved.\n",
      "Epoch 12/100 — Train Loss: 58339.6688, Validation Loss: 67338.8220\n",
      "Learning rate: 0.000100\n",
      "Best model saved.\n",
      "Epoch 13/100 — Train Loss: 57002.0268, Validation Loss: 74469.8178\n",
      "Learning rate: 0.000100\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch 14/100 — Train Loss: 55251.2957, Validation Loss: 67114.9691\n",
      "Learning rate: 0.000100\n",
      "Best model saved.\n",
      "Epoch 15/100 — Train Loss: 54222.3628, Validation Loss: 67570.6600\n",
      "Learning rate: 0.000100\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch 16/100 — Train Loss: 52840.2434, Validation Loss: 62324.6650\n",
      "Learning rate: 0.000100\n",
      "Best model saved.\n",
      "Epoch 17/100 — Train Loss: 51698.9293, Validation Loss: 56985.9705\n",
      "Learning rate: 0.000100\n",
      "Best model saved.\n",
      "Epoch 18/100 — Train Loss: 50952.3578, Validation Loss: 62140.3200\n",
      "Learning rate: 0.000100\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch 19/100 — Train Loss: 49924.4368, Validation Loss: 61948.2174\n",
      "Learning rate: 0.000100\n",
      "No improvement for 2 epoch(s).\n",
      "Epoch 20/100 — Train Loss: 48818.6429, Validation Loss: 59132.0856\n",
      "Learning rate: 0.000100\n",
      "No improvement for 3 epoch(s).\n",
      "Epoch 21/100 — Train Loss: 47943.9657, Validation Loss: 56419.6344\n",
      "Learning rate: 0.000100\n",
      "Best model saved.\n",
      "Epoch 22/100 — Train Loss: 46919.0614, Validation Loss: 56902.5488\n",
      "Learning rate: 0.000100\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch 23/100 — Train Loss: 46961.1823, Validation Loss: 64350.5037\n",
      "Learning rate: 0.000100\n",
      "No improvement for 2 epoch(s).\n",
      "Epoch 24/100 — Train Loss: 45494.1540, Validation Loss: 54706.9587\n",
      "Learning rate: 0.000100\n",
      "Best model saved.\n",
      "Epoch 25/100 — Train Loss: 44441.0769, Validation Loss: 56248.5451\n",
      "Learning rate: 0.000100\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch 26/100 — Train Loss: 43343.0765, Validation Loss: 60960.5188\n",
      "Learning rate: 0.000100\n",
      "No improvement for 2 epoch(s).\n",
      "Epoch 27/100 — Train Loss: 43115.1511, Validation Loss: 47539.2469\n",
      "Learning rate: 0.000100\n",
      "Best model saved.\n",
      "Epoch 28/100 — Train Loss: 42082.0385, Validation Loss: 51078.7951\n",
      "Learning rate: 0.000100\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch 29/100 — Train Loss: 41328.2481, Validation Loss: 67606.2152\n",
      "Learning rate: 0.000100\n",
      "No improvement for 2 epoch(s).\n",
      "Epoch 30/100 — Train Loss: 40666.4113, Validation Loss: 47479.6338\n",
      "Learning rate: 0.000100\n",
      "Best model saved.\n",
      "Epoch 31/100 — Train Loss: 39644.9572, Validation Loss: 45564.0166\n",
      "Learning rate: 0.000100\n",
      "Best model saved.\n",
      "Epoch 32/100 — Train Loss: 39192.9009, Validation Loss: 42272.9017\n",
      "Learning rate: 0.000100\n",
      "Best model saved.\n",
      "Epoch 33/100 — Train Loss: 38665.7958, Validation Loss: 52512.7897\n",
      "Learning rate: 0.000100\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch 34/100 — Train Loss: 37231.7109, Validation Loss: 54254.6414\n",
      "Learning rate: 0.000100\n",
      "No improvement for 2 epoch(s).\n",
      "Epoch 35/100 — Train Loss: 37217.9310, Validation Loss: 35993.8162\n",
      "Learning rate: 0.000100\n",
      "Best model saved.\n",
      "Epoch 36/100 — Train Loss: 36229.2932, Validation Loss: 40091.1537\n",
      "Learning rate: 0.000100\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch 37/100 — Train Loss: 35384.8984, Validation Loss: 48358.6432\n",
      "Learning rate: 0.000100\n",
      "No improvement for 2 epoch(s).\n",
      "Epoch 38/100 — Train Loss: 34772.6048, Validation Loss: 43329.8043\n",
      "Learning rate: 0.000100\n",
      "No improvement for 3 epoch(s).\n",
      "Epoch 39/100 — Train Loss: 34043.8652, Validation Loss: 59884.6208\n",
      "Learning rate: 0.000100\n",
      "No improvement for 4 epoch(s).\n",
      "Epoch 40/100 — Train Loss: 33285.3030, Validation Loss: 50252.3401\n",
      "Learning rate: 0.000100\n",
      "No improvement for 5 epoch(s).\n",
      "Epoch 41/100 — Train Loss: 33073.1133, Validation Loss: 34518.9338\n",
      "Learning rate: 0.000100\n",
      "Best model saved.\n",
      "Epoch 42/100 — Train Loss: 32191.6173, Validation Loss: 53567.8023\n",
      "Learning rate: 0.000100\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch 43/100 — Train Loss: 32382.9573, Validation Loss: 37351.7319\n",
      "Learning rate: 0.000100\n",
      "No improvement for 2 epoch(s).\n",
      "Epoch 44/100 — Train Loss: 30993.1552, Validation Loss: 39434.8712\n",
      "Learning rate: 0.000100\n",
      "No improvement for 3 epoch(s).\n",
      "Epoch 45/100 — Train Loss: 30350.4284, Validation Loss: 34375.8630\n",
      "Learning rate: 0.000100\n",
      "Best model saved.\n",
      "Epoch 46/100 — Train Loss: 29828.5469, Validation Loss: 38861.3459\n",
      "Learning rate: 0.000100\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch 47/100 — Train Loss: 27852.5142, Validation Loss: 41993.4046\n",
      "Learning rate: 0.000100\n",
      "No improvement for 2 epoch(s).\n",
      "Epoch 48/100 — Train Loss: 28887.6706, Validation Loss: 44728.9789\n",
      "Learning rate: 0.000100\n",
      "No improvement for 3 epoch(s).\n",
      "Epoch 49/100 — Train Loss: 28709.9961, Validation Loss: 39873.9403\n",
      "Learning rate: 0.000100\n",
      "No improvement for 4 epoch(s).\n",
      "Epoch 50/100 — Train Loss: 27594.6890, Validation Loss: 49856.0100\n",
      "Learning rate: 0.000100\n",
      "No improvement for 5 epoch(s).\n",
      "Epoch 51/100 — Train Loss: 27514.9077, Validation Loss: 31186.6824\n",
      "Learning rate: 0.000100\n",
      "Best model saved.\n",
      "Epoch 52/100 — Train Loss: 27238.5110, Validation Loss: 30882.0692\n",
      "Learning rate: 0.000100\n",
      "Best model saved.\n",
      "Epoch 53/100 — Train Loss: 25511.7169, Validation Loss: 30282.9360\n",
      "Learning rate: 0.000100\n",
      "Best model saved.\n",
      "Epoch 54/100 — Train Loss: 26290.3334, Validation Loss: 26378.0578\n",
      "Learning rate: 0.000100\n",
      "Best model saved.\n",
      "Epoch 55/100 — Train Loss: 25656.3196, Validation Loss: 29543.7432\n",
      "Learning rate: 0.000100\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch 56/100 — Train Loss: 24281.6765, Validation Loss: 41866.7876\n",
      "Learning rate: 0.000100\n",
      "No improvement for 2 epoch(s).\n",
      "Epoch 57/100 — Train Loss: 24120.5978, Validation Loss: 25548.1559\n",
      "Learning rate: 0.000100\n",
      "Best model saved.\n",
      "Epoch 58/100 — Train Loss: 23867.0189, Validation Loss: 25907.8798\n",
      "Learning rate: 0.000100\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch 59/100 — Train Loss: 22625.2120, Validation Loss: 41357.6840\n",
      "Learning rate: 0.000100\n",
      "No improvement for 2 epoch(s).\n",
      "Epoch 60/100 — Train Loss: 23294.5986, Validation Loss: 20859.4073\n",
      "Learning rate: 0.000100\n",
      "Best model saved.\n",
      "Epoch 61/100 — Train Loss: 22906.4318, Validation Loss: 54610.4824\n",
      "Learning rate: 0.000100\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch 62/100 — Train Loss: 22219.0977, Validation Loss: 21922.8679\n",
      "Learning rate: 0.000100\n",
      "No improvement for 2 epoch(s).\n",
      "Epoch 63/100 — Train Loss: 22267.1937, Validation Loss: 25582.0293\n",
      "Learning rate: 0.000100\n",
      "No improvement for 3 epoch(s).\n",
      "Epoch 64/100 — Train Loss: 21512.2221, Validation Loss: 36630.7780\n",
      "Learning rate: 0.000100\n",
      "No improvement for 4 epoch(s).\n",
      "Epoch 65/100 — Train Loss: 20932.4008, Validation Loss: 19595.9834\n",
      "Learning rate: 0.000100\n",
      "Best model saved.\n",
      "Epoch 66/100 — Train Loss: 21994.5804, Validation Loss: 31747.8111\n",
      "Learning rate: 0.000100\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch 67/100 — Train Loss: 21005.1021, Validation Loss: 50609.5906\n",
      "Learning rate: 0.000100\n",
      "No improvement for 2 epoch(s).\n",
      "Epoch 68/100 — Train Loss: 20432.9422, Validation Loss: 29041.4697\n",
      "Learning rate: 0.000100\n",
      "No improvement for 3 epoch(s).\n",
      "Epoch 69/100 — Train Loss: 19964.4612, Validation Loss: 23775.7988\n",
      "Learning rate: 0.000100\n",
      "No improvement for 4 epoch(s).\n",
      "Epoch 70/100 — Train Loss: 19568.6023, Validation Loss: 24392.0135\n",
      "Learning rate: 0.000100\n",
      "No improvement for 5 epoch(s).\n",
      "Epoch 71/100 — Train Loss: 20331.2460, Validation Loss: 19386.8898\n",
      "Learning rate: 0.000100\n",
      "Best model saved.\n",
      "Epoch 72/100 — Train Loss: 19673.6580, Validation Loss: 22552.9667\n",
      "Learning rate: 0.000100\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch 73/100 — Train Loss: 19191.8352, Validation Loss: 25403.1503\n",
      "Learning rate: 0.000100\n",
      "No improvement for 2 epoch(s).\n",
      "Epoch 74/100 — Train Loss: 19372.8991, Validation Loss: 19355.7121\n",
      "Learning rate: 0.000100\n",
      "Best model saved.\n",
      "Epoch 75/100 — Train Loss: 18590.3821, Validation Loss: 24233.4869\n",
      "Learning rate: 0.000100\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch 76/100 — Train Loss: 18311.6976, Validation Loss: 20152.6506\n",
      "Learning rate: 0.000100\n",
      "No improvement for 2 epoch(s).\n",
      "Epoch 77/100 — Train Loss: 19727.1233, Validation Loss: 19361.9361\n",
      "Learning rate: 0.000100\n",
      "No improvement for 3 epoch(s).\n",
      "Epoch 78/100 — Train Loss: 19211.5064, Validation Loss: 19097.0876\n",
      "Learning rate: 0.000100\n",
      "Best model saved.\n",
      "Epoch 79/100 — Train Loss: 19229.0805, Validation Loss: 39332.0644\n",
      "Learning rate: 0.000100\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch 80/100 — Train Loss: 18547.3736, Validation Loss: 46650.1290\n",
      "Learning rate: 0.000100\n",
      "No improvement for 2 epoch(s).\n",
      "Epoch 81/100 — Train Loss: 20016.3177, Validation Loss: 42465.7798\n",
      "Learning rate: 0.000100\n",
      "No improvement for 3 epoch(s).\n",
      "Epoch 82/100 — Train Loss: 19081.9756, Validation Loss: 30621.5410\n",
      "Learning rate: 0.000100\n",
      "No improvement for 4 epoch(s).\n",
      "Epoch 83/100 — Train Loss: 17747.1292, Validation Loss: 37141.2689\n",
      "Learning rate: 0.000100\n",
      "No improvement for 5 epoch(s).\n",
      "Epoch 84/100 — Train Loss: 18772.7707, Validation Loss: 18721.0416\n",
      "Learning rate: 0.000100\n",
      "Best model saved.\n",
      "Epoch 85/100 — Train Loss: 18740.8722, Validation Loss: 91726.3373\n",
      "Learning rate: 0.000100\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch 86/100 — Train Loss: 17937.8240, Validation Loss: 15853.7414\n",
      "Learning rate: 0.000100\n",
      "Best model saved.\n",
      "Epoch 87/100 — Train Loss: 18539.4532, Validation Loss: 24201.5997\n",
      "Learning rate: 0.000100\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch 88/100 — Train Loss: 17585.1574, Validation Loss: 24244.9986\n",
      "Learning rate: 0.000100\n",
      "No improvement for 2 epoch(s).\n",
      "Epoch 89/100 — Train Loss: 18258.4478, Validation Loss: 19497.1938\n",
      "Learning rate: 0.000100\n",
      "No improvement for 3 epoch(s).\n",
      "Epoch 90/100 — Train Loss: 18247.9931, Validation Loss: 15922.2652\n",
      "Learning rate: 0.000100\n",
      "No improvement for 4 epoch(s).\n",
      "Epoch 91/100 — Train Loss: 18196.7331, Validation Loss: 16875.8475\n",
      "Learning rate: 0.000100\n",
      "No improvement for 5 epoch(s).\n",
      "Epoch 92/100 — Train Loss: 19067.3651, Validation Loss: 18536.8778\n",
      "Learning rate: 0.000050\n",
      "No improvement for 6 epoch(s).\n",
      "Epoch 93/100 — Train Loss: 17189.5068, Validation Loss: 16672.8117\n",
      "Learning rate: 0.000050\n",
      "No improvement for 7 epoch(s).\n",
      "Early stopping triggered after 93 epochs.\n",
      "\n",
      "🔁 Training model 4/5 with seed 45\n",
      "Epoch 1/100 — Train Loss: 66249.3032, Validation Loss: 54164.2304\n",
      "Learning rate: 0.000100\n",
      "Best model saved.\n",
      "Epoch 2/100 — Train Loss: 66002.1964, Validation Loss: 54026.9425\n",
      "Learning rate: 0.000100\n",
      "Best model saved.\n",
      "Epoch 3/100 — Train Loss: 65778.8686, Validation Loss: 53801.8438\n",
      "Learning rate: 0.000100\n",
      "Best model saved.\n",
      "Epoch 4/100 — Train Loss: 65572.9976, Validation Loss: 53571.8351\n",
      "Learning rate: 0.000100\n",
      "Best model saved.\n",
      "Epoch 5/100 — Train Loss: 65367.1400, Validation Loss: 53556.1088\n",
      "Learning rate: 0.000100\n",
      "Best model saved.\n",
      "Epoch 6/100 — Train Loss: 65196.6242, Validation Loss: 53375.1818\n",
      "Learning rate: 0.000100\n",
      "Best model saved.\n",
      "Epoch 7/100 — Train Loss: 64967.8023, Validation Loss: 52703.0168\n",
      "Learning rate: 0.000100\n",
      "Best model saved.\n",
      "Epoch 8/100 — Train Loss: 64732.0409, Validation Loss: 52830.1924\n",
      "Learning rate: 0.000100\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch 9/100 — Train Loss: 64272.6254, Validation Loss: 52466.1805\n",
      "Learning rate: 0.000100\n",
      "Best model saved.\n",
      "Epoch 10/100 — Train Loss: 63766.0430, Validation Loss: 50531.5808\n",
      "Learning rate: 0.000100\n",
      "Best model saved.\n",
      "Epoch 11/100 — Train Loss: 62672.4022, Validation Loss: 47991.4762\n",
      "Learning rate: 0.000100\n",
      "Best model saved.\n",
      "Epoch 12/100 — Train Loss: 61711.0749, Validation Loss: 47690.6758\n",
      "Learning rate: 0.000100\n",
      "Best model saved.\n",
      "Epoch 13/100 — Train Loss: 60157.6802, Validation Loss: 53987.3861\n",
      "Learning rate: 0.000100\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch 14/100 — Train Loss: 58958.3055, Validation Loss: 48052.2349\n",
      "Learning rate: 0.000100\n",
      "No improvement for 2 epoch(s).\n",
      "Epoch 15/100 — Train Loss: 57793.9193, Validation Loss: 53111.8208\n",
      "Learning rate: 0.000100\n",
      "No improvement for 3 epoch(s).\n",
      "Epoch 16/100 — Train Loss: 56650.4723, Validation Loss: 44434.6910\n",
      "Learning rate: 0.000100\n",
      "Best model saved.\n",
      "Epoch 17/100 — Train Loss: 55365.2831, Validation Loss: 40512.3868\n",
      "Learning rate: 0.000100\n",
      "Best model saved.\n",
      "Epoch 18/100 — Train Loss: 54582.6905, Validation Loss: 45383.1044\n",
      "Learning rate: 0.000100\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch 19/100 — Train Loss: 53732.8885, Validation Loss: 46454.7704\n",
      "Learning rate: 0.000100\n",
      "No improvement for 2 epoch(s).\n",
      "Epoch 20/100 — Train Loss: 52777.2078, Validation Loss: 42150.3234\n",
      "Learning rate: 0.000100\n",
      "No improvement for 3 epoch(s).\n",
      "Epoch 21/100 — Train Loss: 51525.9582, Validation Loss: 36568.0818\n",
      "Learning rate: 0.000100\n",
      "Best model saved.\n",
      "Epoch 22/100 — Train Loss: 50868.7770, Validation Loss: 40575.4509\n",
      "Learning rate: 0.000100\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch 23/100 — Train Loss: 49739.0901, Validation Loss: 50287.9258\n",
      "Learning rate: 0.000100\n",
      "No improvement for 2 epoch(s).\n",
      "Epoch 24/100 — Train Loss: 48753.2608, Validation Loss: 41233.6973\n",
      "Learning rate: 0.000100\n",
      "No improvement for 3 epoch(s).\n",
      "Epoch 25/100 — Train Loss: 48321.6004, Validation Loss: 33478.6515\n",
      "Learning rate: 0.000100\n",
      "Best model saved.\n",
      "Epoch 26/100 — Train Loss: 46686.5213, Validation Loss: 36240.6448\n",
      "Learning rate: 0.000100\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch 27/100 — Train Loss: 46201.3656, Validation Loss: 34990.4051\n",
      "Learning rate: 0.000100\n",
      "No improvement for 2 epoch(s).\n",
      "Epoch 28/100 — Train Loss: 45183.3079, Validation Loss: 39355.0140\n",
      "Learning rate: 0.000100\n",
      "No improvement for 3 epoch(s).\n",
      "Epoch 29/100 — Train Loss: 44663.1907, Validation Loss: 42732.8599\n",
      "Learning rate: 0.000100\n",
      "No improvement for 4 epoch(s).\n",
      "Epoch 30/100 — Train Loss: 43674.8673, Validation Loss: 33498.3041\n",
      "Learning rate: 0.000100\n",
      "No improvement for 5 epoch(s).\n",
      "Epoch 31/100 — Train Loss: 42802.6661, Validation Loss: 33671.3893\n",
      "Learning rate: 0.000050\n",
      "No improvement for 6 epoch(s).\n",
      "Epoch 32/100 — Train Loss: 42101.9785, Validation Loss: 38879.3658\n",
      "Learning rate: 0.000050\n",
      "No improvement for 7 epoch(s).\n",
      "Early stopping triggered after 32 epochs.\n",
      "\n",
      "🔁 Training model 5/5 with seed 46\n",
      "Epoch 1/100 — Train Loss: 64164.3824, Validation Loss: 61942.2185\n",
      "Learning rate: 0.000100\n",
      "Best model saved.\n",
      "Epoch 2/100 — Train Loss: 63907.7632, Validation Loss: 61691.4699\n",
      "Learning rate: 0.000100\n",
      "Best model saved.\n",
      "Epoch 3/100 — Train Loss: 63642.9340, Validation Loss: 61495.2387\n",
      "Learning rate: 0.000100\n",
      "Best model saved.\n",
      "Epoch 4/100 — Train Loss: 63384.8450, Validation Loss: 61372.5040\n",
      "Learning rate: 0.000100\n",
      "Best model saved.\n",
      "Epoch 5/100 — Train Loss: 63087.0471, Validation Loss: 61005.7858\n",
      "Learning rate: 0.000100\n",
      "Best model saved.\n",
      "Epoch 6/100 — Train Loss: 62564.3374, Validation Loss: 58925.6622\n",
      "Learning rate: 0.000100\n",
      "Best model saved.\n",
      "Epoch 7/100 — Train Loss: 61626.6249, Validation Loss: 59989.5921\n",
      "Learning rate: 0.000100\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch 8/100 — Train Loss: 60279.7113, Validation Loss: 55895.9714\n",
      "Learning rate: 0.000100\n",
      "Best model saved.\n",
      "Epoch 9/100 — Train Loss: 58954.0267, Validation Loss: 52550.4945\n",
      "Learning rate: 0.000100\n",
      "Best model saved.\n",
      "Epoch 10/100 — Train Loss: 57863.9062, Validation Loss: 52101.7846\n",
      "Learning rate: 0.000100\n",
      "Best model saved.\n",
      "Epoch 11/100 — Train Loss: 56917.9288, Validation Loss: 59221.5078\n",
      "Learning rate: 0.000100\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch 12/100 — Train Loss: 56061.8386, Validation Loss: 52955.9432\n",
      "Learning rate: 0.000100\n",
      "No improvement for 2 epoch(s).\n",
      "Epoch 13/100 — Train Loss: 55044.7368, Validation Loss: 54960.6050\n",
      "Learning rate: 0.000100\n",
      "No improvement for 3 epoch(s).\n",
      "Epoch 14/100 — Train Loss: 54051.6951, Validation Loss: 62268.4145\n",
      "Learning rate: 0.000100\n",
      "No improvement for 4 epoch(s).\n",
      "Epoch 15/100 — Train Loss: 53218.6969, Validation Loss: 54903.7876\n",
      "Learning rate: 0.000100\n",
      "No improvement for 5 epoch(s).\n",
      "Epoch 16/100 — Train Loss: 52146.0486, Validation Loss: 52174.6668\n",
      "Learning rate: 0.000050\n",
      "No improvement for 6 epoch(s).\n",
      "Epoch 17/100 — Train Loss: 51549.7041, Validation Loss: 44317.9429\n",
      "Learning rate: 0.000050\n",
      "Best model saved.\n",
      "Epoch 18/100 — Train Loss: 51243.9520, Validation Loss: 48353.0449\n",
      "Learning rate: 0.000050\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch 19/100 — Train Loss: 50833.9887, Validation Loss: 49340.1079\n",
      "Learning rate: 0.000050\n",
      "No improvement for 2 epoch(s).\n",
      "Epoch 20/100 — Train Loss: 50470.2381, Validation Loss: 52045.4474\n",
      "Learning rate: 0.000050\n",
      "No improvement for 3 epoch(s).\n",
      "Epoch 21/100 — Train Loss: 49794.9308, Validation Loss: 46441.9575\n",
      "Learning rate: 0.000050\n",
      "No improvement for 4 epoch(s).\n",
      "Epoch 22/100 — Train Loss: 49760.3224, Validation Loss: 43396.8635\n",
      "Learning rate: 0.000050\n",
      "Best model saved.\n",
      "Epoch 23/100 — Train Loss: 48920.9354, Validation Loss: 42249.8158\n",
      "Learning rate: 0.000050\n",
      "Best model saved.\n",
      "Epoch 24/100 — Train Loss: 48559.0720, Validation Loss: 44683.7793\n",
      "Learning rate: 0.000050\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch 25/100 — Train Loss: 48102.6632, Validation Loss: 38432.6187\n",
      "Learning rate: 0.000050\n",
      "Best model saved.\n",
      "Epoch 26/100 — Train Loss: 47815.1581, Validation Loss: 47456.9445\n",
      "Learning rate: 0.000050\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch 27/100 — Train Loss: 47486.9605, Validation Loss: 46596.6628\n",
      "Learning rate: 0.000050\n",
      "No improvement for 2 epoch(s).\n",
      "Epoch 28/100 — Train Loss: 46718.8136, Validation Loss: 42241.0828\n",
      "Learning rate: 0.000050\n",
      "No improvement for 3 epoch(s).\n",
      "Epoch 29/100 — Train Loss: 46321.2902, Validation Loss: 41102.4291\n",
      "Learning rate: 0.000050\n",
      "No improvement for 4 epoch(s).\n",
      "Epoch 30/100 — Train Loss: 46654.5488, Validation Loss: 43824.8810\n",
      "Learning rate: 0.000050\n",
      "No improvement for 5 epoch(s).\n",
      "Epoch 31/100 — Train Loss: 46055.0970, Validation Loss: 39882.5890\n",
      "Learning rate: 0.000025\n",
      "No improvement for 6 epoch(s).\n",
      "Epoch 32/100 — Train Loss: 45562.3153, Validation Loss: 42549.1801\n",
      "Learning rate: 0.000025\n",
      "No improvement for 7 epoch(s).\n",
      "Early stopping triggered after 32 epochs.\n"
     ]
    }
   ],
   "source": [
    "#############################################\n",
    "# Train the resnet model \n",
    "#############################################\n",
    "resnet_models = train_deep_ensemble(num_models=5,model_name='resnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300f5164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SNR -> MAE: 115.5818, RMSE: 180.9482, R2: 0.4706\n",
      "SNR -> MAE: 136.5066, RMSE: 219.0683, R2: 0.2241\n",
      "SNR -> MAE: 79.3188, RMSE: 117.2559, R2: 0.7777\n",
      "SNR -> MAE: 137.8658, RMSE: 221.3034, R2: 0.2081\n",
      "SNR -> MAE: 136.0369, RMSE: 219.1944, R2: 0.2232\n"
     ]
    }
   ],
   "source": [
    "################################################\n",
    "# Results of each individual Resnet model\n",
    "################################################\n",
    "\n",
    "for i in range(5):\n",
    "    seed = 42\n",
    "    _, val_loader = get_data_loaders(seed=seed, test_ind=False, model_name='resnet')\n",
    "    evaluate_model(model=resnet_models[i], dataloader=val_loader, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37fd802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔁 Training model 1/5 with seed 42\n",
      "Epoch 1/100 — Train Loss: 55654.7663, Validation Loss: 68966.9488\n",
      "Learning rate: 0.001000\n",
      "Best model saved.\n",
      "Epoch 2/100 — Train Loss: 55569.8090, Validation Loss: 61135.3118\n",
      "Learning rate: 0.001000\n",
      "Best model saved.\n",
      "Epoch 3/100 — Train Loss: 55044.1738, Validation Loss: 62999.9551\n",
      "Learning rate: 0.001000\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch 4/100 — Train Loss: 55234.9219, Validation Loss: 60939.9731\n",
      "Learning rate: 0.001000\n",
      "Best model saved.\n",
      "Epoch 5/100 — Train Loss: 54493.9528, Validation Loss: 61625.4676\n",
      "Learning rate: 0.001000\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch 6/100 — Train Loss: 54254.0632, Validation Loss: 59931.9180\n",
      "Learning rate: 0.001000\n",
      "Best model saved.\n",
      "Epoch 7/100 — Train Loss: 53940.9768, Validation Loss: 59566.0296\n",
      "Learning rate: 0.001000\n",
      "Best model saved.\n",
      "Epoch 8/100 — Train Loss: 53621.3525, Validation Loss: 60182.3508\n",
      "Learning rate: 0.001000\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch 9/100 — Train Loss: 53400.3672, Validation Loss: 59523.2853\n",
      "Learning rate: 0.001000\n",
      "Best model saved.\n",
      "Epoch 10/100 — Train Loss: 53901.0287, Validation Loss: 67548.0119\n",
      "Learning rate: 0.001000\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch 11/100 — Train Loss: 54384.2505, Validation Loss: 59529.4822\n",
      "Learning rate: 0.001000\n",
      "No improvement for 2 epoch(s).\n",
      "Epoch 12/100 — Train Loss: 53039.8895, Validation Loss: 58763.8251\n",
      "Learning rate: 0.001000\n",
      "Best model saved.\n",
      "Epoch 13/100 — Train Loss: 52846.5653, Validation Loss: 58172.2379\n",
      "Learning rate: 0.001000\n",
      "Best model saved.\n",
      "Epoch 14/100 — Train Loss: 52123.0019, Validation Loss: 57940.9282\n",
      "Learning rate: 0.001000\n",
      "Best model saved.\n",
      "Epoch 15/100 — Train Loss: 50566.8034, Validation Loss: 54381.7600\n",
      "Learning rate: 0.001000\n",
      "Best model saved.\n",
      "Epoch 16/100 — Train Loss: 45597.7878, Validation Loss: 44598.7850\n",
      "Learning rate: 0.001000\n",
      "Best model saved.\n",
      "Epoch 17/100 — Train Loss: 34662.8950, Validation Loss: 29995.6589\n",
      "Learning rate: 0.001000\n",
      "Best model saved.\n",
      "Epoch 18/100 — Train Loss: 26286.8647, Validation Loss: 25534.7093\n",
      "Learning rate: 0.001000\n",
      "Best model saved.\n",
      "Epoch 19/100 — Train Loss: 22191.8269, Validation Loss: 22515.4393\n",
      "Learning rate: 0.001000\n",
      "Best model saved.\n",
      "Epoch 20/100 — Train Loss: 21388.2006, Validation Loss: 21744.4424\n",
      "Learning rate: 0.001000\n",
      "Best model saved.\n",
      "Epoch 21/100 — Train Loss: 21858.5617, Validation Loss: 21872.0659\n",
      "Learning rate: 0.001000\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch 22/100 — Train Loss: 21733.4697, Validation Loss: 22241.6730\n",
      "Learning rate: 0.001000\n",
      "No improvement for 2 epoch(s).\n",
      "Epoch 23/100 — Train Loss: 21005.0475, Validation Loss: 21630.4618\n",
      "Learning rate: 0.001000\n",
      "Best model saved.\n",
      "Epoch 24/100 — Train Loss: 20911.3804, Validation Loss: 21660.6308\n",
      "Learning rate: 0.001000\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch 25/100 — Train Loss: 20676.7783, Validation Loss: 21485.1438\n",
      "Learning rate: 0.001000\n",
      "Best model saved.\n",
      "Epoch 26/100 — Train Loss: 20637.3871, Validation Loss: 21448.0778\n",
      "Learning rate: 0.001000\n",
      "Best model saved.\n",
      "Epoch 27/100 — Train Loss: 20421.5132, Validation Loss: 21521.9769\n",
      "Learning rate: 0.001000\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch 28/100 — Train Loss: 21063.3807, Validation Loss: 24431.8837\n",
      "Learning rate: 0.001000\n",
      "No improvement for 2 epoch(s).\n",
      "Epoch 29/100 — Train Loss: 20483.4894, Validation Loss: 24003.8807\n",
      "Learning rate: 0.001000\n",
      "No improvement for 3 epoch(s).\n",
      "Epoch 30/100 — Train Loss: 20478.1929, Validation Loss: 25530.1027\n",
      "Learning rate: 0.001000\n",
      "No improvement for 4 epoch(s).\n",
      "Epoch 31/100 — Train Loss: 21086.5206, Validation Loss: 21303.0813\n",
      "Learning rate: 0.001000\n",
      "Best model saved.\n",
      "Epoch 32/100 — Train Loss: 20717.6486, Validation Loss: 21780.2182\n",
      "Learning rate: 0.001000\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch 33/100 — Train Loss: 20527.8506, Validation Loss: 21312.3244\n",
      "Learning rate: 0.001000\n",
      "No improvement for 2 epoch(s).\n",
      "Epoch 34/100 — Train Loss: 20757.4746, Validation Loss: 22456.7722\n",
      "Learning rate: 0.001000\n",
      "No improvement for 3 epoch(s).\n",
      "Epoch 35/100 — Train Loss: 20632.3401, Validation Loss: 21366.9153\n",
      "Learning rate: 0.001000\n",
      "No improvement for 4 epoch(s).\n",
      "Epoch 36/100 — Train Loss: 20573.0335, Validation Loss: 22829.5046\n",
      "Learning rate: 0.001000\n",
      "No improvement for 5 epoch(s).\n",
      "Epoch 37/100 — Train Loss: 20400.7419, Validation Loss: 24543.9739\n",
      "Learning rate: 0.000500\n",
      "No improvement for 6 epoch(s).\n",
      "Epoch 38/100 — Train Loss: 20554.8548, Validation Loss: 21227.5700\n",
      "Learning rate: 0.000500\n",
      "Best model saved.\n",
      "Epoch 39/100 — Train Loss: 20560.7414, Validation Loss: 21393.1594\n",
      "Learning rate: 0.000500\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch 40/100 — Train Loss: 20196.3291, Validation Loss: 22107.9937\n",
      "Learning rate: 0.000500\n",
      "No improvement for 2 epoch(s).\n",
      "Epoch 41/100 — Train Loss: 20329.4046, Validation Loss: 21675.8089\n",
      "Learning rate: 0.000500\n",
      "No improvement for 3 epoch(s).\n",
      "Epoch 42/100 — Train Loss: 20094.9550, Validation Loss: 21210.3828\n",
      "Learning rate: 0.000500\n",
      "Best model saved.\n",
      "Epoch 43/100 — Train Loss: 20266.5520, Validation Loss: 22791.5560\n",
      "Learning rate: 0.000500\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch 44/100 — Train Loss: 20321.8210, Validation Loss: 21189.3057\n",
      "Learning rate: 0.000500\n",
      "Best model saved.\n",
      "Epoch 45/100 — Train Loss: 20189.3057, Validation Loss: 21837.8836\n",
      "Learning rate: 0.000500\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch 46/100 — Train Loss: 20278.3914, Validation Loss: 21955.1121\n",
      "Learning rate: 0.000500\n",
      "No improvement for 2 epoch(s).\n",
      "Epoch 47/100 — Train Loss: 20303.7368, Validation Loss: 22524.4764\n",
      "Learning rate: 0.000500\n",
      "No improvement for 3 epoch(s).\n",
      "Epoch 48/100 — Train Loss: 20464.8512, Validation Loss: 21274.5916\n",
      "Learning rate: 0.000500\n",
      "No improvement for 4 epoch(s).\n",
      "Epoch 49/100 — Train Loss: 20240.4654, Validation Loss: 21251.0884\n",
      "Learning rate: 0.000500\n",
      "No improvement for 5 epoch(s).\n",
      "Epoch 50/100 — Train Loss: 20286.9197, Validation Loss: 21825.7163\n",
      "Learning rate: 0.000250\n",
      "No improvement for 6 epoch(s).\n",
      "Epoch 51/100 — Train Loss: 20113.7456, Validation Loss: 21190.4930\n",
      "Learning rate: 0.000250\n",
      "No improvement for 7 epoch(s).\n",
      "Early stopping triggered after 51 epochs.\n",
      "\n",
      "🔁 Training model 2/5 with seed 43\n",
      "Epoch 1/100 — Train Loss: 57733.7558, Validation Loss: 57113.9777\n",
      "Learning rate: 0.001000\n",
      "Best model saved.\n",
      "Epoch 2/100 — Train Loss: 55537.3779, Validation Loss: 55616.8744\n",
      "Learning rate: 0.001000\n",
      "Best model saved.\n",
      "Epoch 3/100 — Train Loss: 54353.4579, Validation Loss: 55073.6638\n",
      "Learning rate: 0.001000\n",
      "Best model saved.\n",
      "Epoch 4/100 — Train Loss: 54108.2967, Validation Loss: 54940.4525\n",
      "Learning rate: 0.001000\n",
      "Best model saved.\n",
      "Epoch 5/100 — Train Loss: 54018.3236, Validation Loss: 54413.1714\n",
      "Learning rate: 0.001000\n",
      "Best model saved.\n",
      "Epoch 6/100 — Train Loss: 53254.4487, Validation Loss: 53693.2814\n",
      "Learning rate: 0.001000\n",
      "Best model saved.\n",
      "Epoch 7/100 — Train Loss: 52187.6437, Validation Loss: 52887.6937\n",
      "Learning rate: 0.001000\n",
      "Best model saved.\n",
      "Epoch 8/100 — Train Loss: 53890.2207, Validation Loss: 50079.7869\n",
      "Learning rate: 0.001000\n",
      "Best model saved.\n",
      "Epoch 9/100 — Train Loss: 45409.1816, Validation Loss: 40697.2077\n",
      "Learning rate: 0.001000\n",
      "Best model saved.\n",
      "Epoch 10/100 — Train Loss: 35269.4766, Validation Loss: 30133.1942\n",
      "Learning rate: 0.001000\n",
      "Best model saved.\n",
      "Epoch 11/100 — Train Loss: 25790.3194, Validation Loss: 22891.0872\n",
      "Learning rate: 0.001000\n",
      "Best model saved.\n",
      "Epoch 12/100 — Train Loss: 22526.6841, Validation Loss: 21575.3615\n",
      "Learning rate: 0.001000\n",
      "Best model saved.\n",
      "Epoch 13/100 — Train Loss: 21281.4750, Validation Loss: 21604.1553\n",
      "Learning rate: 0.001000\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch 14/100 — Train Loss: 21074.6413, Validation Loss: 22038.7862\n",
      "Learning rate: 0.001000\n",
      "No improvement for 2 epoch(s).\n",
      "Epoch 15/100 — Train Loss: 21205.5377, Validation Loss: 20695.2030\n",
      "Learning rate: 0.001000\n",
      "Best model saved.\n",
      "Epoch 16/100 — Train Loss: 20751.5746, Validation Loss: 21025.6580\n",
      "Learning rate: 0.001000\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch 17/100 — Train Loss: 21660.3783, Validation Loss: 20815.4481\n",
      "Learning rate: 0.001000\n",
      "No improvement for 2 epoch(s).\n",
      "Epoch 18/100 — Train Loss: 21349.6714, Validation Loss: 20723.8579\n",
      "Learning rate: 0.001000\n",
      "No improvement for 3 epoch(s).\n",
      "Epoch 19/100 — Train Loss: 21005.9775, Validation Loss: 21320.1654\n",
      "Learning rate: 0.001000\n",
      "No improvement for 4 epoch(s).\n",
      "Epoch 20/100 — Train Loss: 20665.6190, Validation Loss: 21643.5609\n",
      "Learning rate: 0.001000\n",
      "No improvement for 5 epoch(s).\n",
      "Epoch 21/100 — Train Loss: 20642.8646, Validation Loss: 21020.4552\n",
      "Learning rate: 0.000500\n",
      "No improvement for 6 epoch(s).\n",
      "Epoch 22/100 — Train Loss: 20615.1892, Validation Loss: 21000.4790\n",
      "Learning rate: 0.000500\n",
      "No improvement for 7 epoch(s).\n",
      "Early stopping triggered after 22 epochs.\n",
      "\n",
      "🔁 Training model 3/5 with seed 44\n",
      "Epoch 1/100 — Train Loss: 54459.6942, Validation Loss: 65350.6214\n",
      "Learning rate: 0.001000\n",
      "Best model saved.\n",
      "Epoch 2/100 — Train Loss: 52932.1466, Validation Loss: 64968.0563\n",
      "Learning rate: 0.001000\n",
      "Best model saved.\n",
      "Epoch 3/100 — Train Loss: 52970.4375, Validation Loss: 64923.7585\n",
      "Learning rate: 0.001000\n",
      "Best model saved.\n",
      "Epoch 4/100 — Train Loss: 51930.0588, Validation Loss: 64509.9593\n",
      "Learning rate: 0.001000\n",
      "Best model saved.\n",
      "Epoch 5/100 — Train Loss: 51488.5251, Validation Loss: 63986.8478\n",
      "Learning rate: 0.001000\n",
      "Best model saved.\n",
      "Epoch 6/100 — Train Loss: 50844.0152, Validation Loss: 63133.8680\n",
      "Learning rate: 0.001000\n",
      "Best model saved.\n",
      "Epoch 7/100 — Train Loss: 49837.2813, Validation Loss: 61061.7994\n",
      "Learning rate: 0.001000\n",
      "Best model saved.\n",
      "Epoch 8/100 — Train Loss: 46893.3675, Validation Loss: 55321.4759\n",
      "Learning rate: 0.001000\n",
      "Best model saved.\n",
      "Epoch 9/100 — Train Loss: 40239.1203, Validation Loss: 44854.3748\n",
      "Learning rate: 0.001000\n",
      "Best model saved.\n",
      "Epoch 10/100 — Train Loss: 30777.8222, Validation Loss: 31343.5273\n",
      "Learning rate: 0.001000\n",
      "Best model saved.\n",
      "Epoch 11/100 — Train Loss: 23987.8415, Validation Loss: 27283.9058\n",
      "Learning rate: 0.001000\n",
      "Best model saved.\n",
      "Epoch 12/100 — Train Loss: 22082.0781, Validation Loss: 29728.7879\n",
      "Learning rate: 0.001000\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch 13/100 — Train Loss: 21077.3985, Validation Loss: 24932.9804\n",
      "Learning rate: 0.001000\n",
      "Best model saved.\n",
      "Epoch 14/100 — Train Loss: 21932.8698, Validation Loss: 23514.0613\n",
      "Learning rate: 0.001000\n",
      "Best model saved.\n",
      "Epoch 15/100 — Train Loss: 21151.4641, Validation Loss: 25415.6686\n",
      "Learning rate: 0.001000\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch 16/100 — Train Loss: 21041.5687, Validation Loss: 21999.1315\n",
      "Learning rate: 0.001000\n",
      "Best model saved.\n",
      "Epoch 17/100 — Train Loss: 20441.8646, Validation Loss: 22507.9960\n",
      "Learning rate: 0.001000\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch 18/100 — Train Loss: 20893.0555, Validation Loss: 22727.9099\n",
      "Learning rate: 0.001000\n",
      "No improvement for 2 epoch(s).\n",
      "Epoch 19/100 — Train Loss: 20699.7617, Validation Loss: 22815.9616\n",
      "Learning rate: 0.001000\n",
      "No improvement for 3 epoch(s).\n",
      "Epoch 20/100 — Train Loss: 20978.9959, Validation Loss: 21682.6308\n",
      "Learning rate: 0.001000\n",
      "Best model saved.\n",
      "Epoch 21/100 — Train Loss: 20601.8163, Validation Loss: 21691.1786\n",
      "Learning rate: 0.001000\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch 22/100 — Train Loss: 20832.6778, Validation Loss: 22116.5437\n",
      "Learning rate: 0.001000\n",
      "No improvement for 2 epoch(s).\n",
      "Epoch 23/100 — Train Loss: 20211.3040, Validation Loss: 21967.7444\n",
      "Learning rate: 0.001000\n",
      "No improvement for 3 epoch(s).\n",
      "Epoch 24/100 — Train Loss: 20447.8629, Validation Loss: 22111.7681\n",
      "Learning rate: 0.001000\n",
      "No improvement for 4 epoch(s).\n",
      "Epoch 25/100 — Train Loss: 20380.0396, Validation Loss: 21585.7756\n",
      "Learning rate: 0.001000\n",
      "Best model saved.\n",
      "Epoch 26/100 — Train Loss: 20309.3955, Validation Loss: 21722.3971\n",
      "Learning rate: 0.001000\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch 27/100 — Train Loss: 20548.9441, Validation Loss: 23510.2302\n",
      "Learning rate: 0.001000\n",
      "No improvement for 2 epoch(s).\n",
      "Epoch 28/100 — Train Loss: 20219.8255, Validation Loss: 21756.5590\n",
      "Learning rate: 0.001000\n",
      "No improvement for 3 epoch(s).\n",
      "Epoch 29/100 — Train Loss: 20512.7374, Validation Loss: 23172.4566\n",
      "Learning rate: 0.001000\n",
      "No improvement for 4 epoch(s).\n",
      "Epoch 30/100 — Train Loss: 20326.7977, Validation Loss: 21396.0140\n",
      "Learning rate: 0.001000\n",
      "Best model saved.\n",
      "Epoch 31/100 — Train Loss: 20745.9179, Validation Loss: 23012.7626\n",
      "Learning rate: 0.001000\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch 32/100 — Train Loss: 20410.1123, Validation Loss: 22402.4682\n",
      "Learning rate: 0.001000\n",
      "No improvement for 2 epoch(s).\n",
      "Epoch 33/100 — Train Loss: 20129.6628, Validation Loss: 24503.4893\n",
      "Learning rate: 0.001000\n",
      "No improvement for 3 epoch(s).\n",
      "Epoch 34/100 — Train Loss: 20310.6414, Validation Loss: 21897.8494\n",
      "Learning rate: 0.001000\n",
      "No improvement for 4 epoch(s).\n",
      "Epoch 35/100 — Train Loss: 20272.1922, Validation Loss: 23340.3033\n",
      "Learning rate: 0.001000\n",
      "No improvement for 5 epoch(s).\n",
      "Epoch 36/100 — Train Loss: 20330.6451, Validation Loss: 21687.0854\n",
      "Learning rate: 0.000500\n",
      "No improvement for 6 epoch(s).\n",
      "Epoch 37/100 — Train Loss: 20017.9874, Validation Loss: 22115.8846\n",
      "Learning rate: 0.000500\n",
      "No improvement for 7 epoch(s).\n",
      "Early stopping triggered after 37 epochs.\n",
      "\n",
      "🔁 Training model 4/5 with seed 45\n",
      "Epoch 1/100 — Train Loss: 58759.0299, Validation Loss: 50366.3433\n",
      "Learning rate: 0.001000\n",
      "Best model saved.\n",
      "Epoch 2/100 — Train Loss: 56402.3239, Validation Loss: 49783.2304\n",
      "Learning rate: 0.001000\n",
      "Best model saved.\n",
      "Epoch 3/100 — Train Loss: 56278.2755, Validation Loss: 48293.3518\n",
      "Learning rate: 0.001000\n",
      "Best model saved.\n",
      "Epoch 4/100 — Train Loss: 55585.3937, Validation Loss: 48127.2591\n",
      "Learning rate: 0.001000\n",
      "Best model saved.\n",
      "Epoch 5/100 — Train Loss: 55124.1874, Validation Loss: 47801.9273\n",
      "Learning rate: 0.001000\n",
      "Best model saved.\n",
      "Epoch 6/100 — Train Loss: 54279.9487, Validation Loss: 45916.3880\n",
      "Learning rate: 0.001000\n",
      "Best model saved.\n",
      "Epoch 7/100 — Train Loss: 51421.3438, Validation Loss: 42577.0127\n",
      "Learning rate: 0.001000\n",
      "Best model saved.\n",
      "Epoch 8/100 — Train Loss: 42734.2270, Validation Loss: 30666.1359\n",
      "Learning rate: 0.001000\n",
      "Best model saved.\n",
      "Epoch 9/100 — Train Loss: 30036.2503, Validation Loss: 24134.0486\n",
      "Learning rate: 0.001000\n",
      "Best model saved.\n",
      "Epoch 10/100 — Train Loss: 24382.9637, Validation Loss: 22425.8428\n",
      "Learning rate: 0.001000\n",
      "Best model saved.\n",
      "Epoch 11/100 — Train Loss: 21774.3201, Validation Loss: 22277.9122\n",
      "Learning rate: 0.001000\n",
      "Best model saved.\n",
      "Epoch 12/100 — Train Loss: 21886.5659, Validation Loss: 20573.9762\n",
      "Learning rate: 0.001000\n",
      "Best model saved.\n",
      "Epoch 13/100 — Train Loss: 20940.9785, Validation Loss: 19739.4153\n",
      "Learning rate: 0.001000\n",
      "Best model saved.\n",
      "Epoch 14/100 — Train Loss: 21556.7234, Validation Loss: 19595.1762\n",
      "Learning rate: 0.001000\n",
      "Best model saved.\n",
      "Epoch 15/100 — Train Loss: 22375.2612, Validation Loss: 19562.9721\n",
      "Learning rate: 0.001000\n",
      "Best model saved.\n",
      "Epoch 16/100 — Train Loss: 21814.1430, Validation Loss: 20465.2238\n",
      "Learning rate: 0.001000\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch 17/100 — Train Loss: 22724.3718, Validation Loss: 20235.0654\n",
      "Learning rate: 0.001000\n",
      "No improvement for 2 epoch(s).\n",
      "Epoch 18/100 — Train Loss: 21117.6866, Validation Loss: 19564.5399\n",
      "Learning rate: 0.001000\n",
      "No improvement for 3 epoch(s).\n",
      "Epoch 19/100 — Train Loss: 21363.8099, Validation Loss: 20211.8610\n",
      "Learning rate: 0.001000\n",
      "No improvement for 4 epoch(s).\n",
      "Epoch 20/100 — Train Loss: 21516.1115, Validation Loss: 19667.1777\n",
      "Learning rate: 0.001000\n",
      "No improvement for 5 epoch(s).\n",
      "Epoch 21/100 — Train Loss: 23521.3573, Validation Loss: 19615.4200\n",
      "Learning rate: 0.000500\n",
      "No improvement for 6 epoch(s).\n",
      "Epoch 22/100 — Train Loss: 20960.5530, Validation Loss: 19509.3931\n",
      "Learning rate: 0.000500\n",
      "Best model saved.\n",
      "Epoch 23/100 — Train Loss: 20917.6596, Validation Loss: 19523.9089\n",
      "Learning rate: 0.000500\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch 24/100 — Train Loss: 20770.3143, Validation Loss: 19996.1942\n",
      "Learning rate: 0.000500\n",
      "No improvement for 2 epoch(s).\n",
      "Epoch 25/100 — Train Loss: 20951.5739, Validation Loss: 19533.2164\n",
      "Learning rate: 0.000500\n",
      "No improvement for 3 epoch(s).\n",
      "Epoch 26/100 — Train Loss: 21093.8111, Validation Loss: 19573.0781\n",
      "Learning rate: 0.000500\n",
      "No improvement for 4 epoch(s).\n",
      "Epoch 27/100 — Train Loss: 21032.7583, Validation Loss: 19574.0335\n",
      "Learning rate: 0.000500\n",
      "No improvement for 5 epoch(s).\n",
      "Epoch 28/100 — Train Loss: 21197.4434, Validation Loss: 20618.4595\n",
      "Learning rate: 0.000250\n",
      "No improvement for 6 epoch(s).\n",
      "Epoch 29/100 — Train Loss: 21252.1321, Validation Loss: 19623.0376\n",
      "Learning rate: 0.000250\n",
      "No improvement for 7 epoch(s).\n",
      "Early stopping triggered after 29 epochs.\n",
      "\n",
      "🔁 Training model 5/5 with seed 46\n",
      "Epoch 1/100 — Train Loss: 58759.0316, Validation Loss: 53890.7885\n",
      "Learning rate: 0.001000\n",
      "Best model saved.\n",
      "Epoch 2/100 — Train Loss: 55789.3336, Validation Loss: 54115.5229\n",
      "Learning rate: 0.001000\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch 3/100 — Train Loss: 54904.6436, Validation Loss: 53505.8935\n",
      "Learning rate: 0.001000\n",
      "Best model saved.\n",
      "Epoch 4/100 — Train Loss: 55083.4652, Validation Loss: 52760.5106\n",
      "Learning rate: 0.001000\n",
      "Best model saved.\n",
      "Epoch 5/100 — Train Loss: 54483.9211, Validation Loss: 52513.3135\n",
      "Learning rate: 0.001000\n",
      "Best model saved.\n",
      "Epoch 6/100 — Train Loss: 54305.7413, Validation Loss: 52119.9312\n",
      "Learning rate: 0.001000\n",
      "Best model saved.\n",
      "Epoch 7/100 — Train Loss: 53530.5011, Validation Loss: 51472.2663\n",
      "Learning rate: 0.001000\n",
      "Best model saved.\n",
      "Epoch 8/100 — Train Loss: 52403.6819, Validation Loss: 49859.9974\n",
      "Learning rate: 0.001000\n",
      "Best model saved.\n",
      "Epoch 9/100 — Train Loss: 49346.8109, Validation Loss: 45134.3588\n",
      "Learning rate: 0.001000\n",
      "Best model saved.\n",
      "Epoch 10/100 — Train Loss: 42668.7609, Validation Loss: 37947.5128\n",
      "Learning rate: 0.001000\n",
      "Best model saved.\n",
      "Epoch 11/100 — Train Loss: 31070.2068, Validation Loss: 25121.5179\n",
      "Learning rate: 0.001000\n",
      "Best model saved.\n",
      "Epoch 12/100 — Train Loss: 109414.4675, Validation Loss: 22638.3943\n",
      "Learning rate: 0.001000\n",
      "Best model saved.\n",
      "Epoch 13/100 — Train Loss: 22785.6713, Validation Loss: 22676.6148\n",
      "Learning rate: 0.001000\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch 14/100 — Train Loss: 21672.3659, Validation Loss: 22170.1509\n",
      "Learning rate: 0.001000\n",
      "Best model saved.\n",
      "Epoch 15/100 — Train Loss: 21130.0793, Validation Loss: 21299.5013\n",
      "Learning rate: 0.001000\n",
      "Best model saved.\n",
      "Epoch 16/100 — Train Loss: 20980.7274, Validation Loss: 21181.6448\n",
      "Learning rate: 0.001000\n",
      "Best model saved.\n",
      "Epoch 17/100 — Train Loss: 20834.4707, Validation Loss: 25077.3680\n",
      "Learning rate: 0.001000\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch 18/100 — Train Loss: 20860.2200, Validation Loss: 21053.7732\n",
      "Learning rate: 0.001000\n",
      "Best model saved.\n",
      "Epoch 19/100 — Train Loss: 21309.6894, Validation Loss: 21654.8207\n",
      "Learning rate: 0.001000\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch 20/100 — Train Loss: 20667.1768, Validation Loss: 21063.8029\n",
      "Learning rate: 0.001000\n",
      "No improvement for 2 epoch(s).\n",
      "Epoch 21/100 — Train Loss: 20928.7926, Validation Loss: 21370.7991\n",
      "Learning rate: 0.001000\n",
      "No improvement for 3 epoch(s).\n",
      "Epoch 22/100 — Train Loss: 20924.0237, Validation Loss: 21158.0400\n",
      "Learning rate: 0.001000\n",
      "No improvement for 4 epoch(s).\n",
      "Epoch 23/100 — Train Loss: 20714.9020, Validation Loss: 21951.4750\n",
      "Learning rate: 0.001000\n",
      "No improvement for 5 epoch(s).\n",
      "Epoch 24/100 — Train Loss: 20959.9869, Validation Loss: 21347.4047\n",
      "Learning rate: 0.000500\n",
      "No improvement for 6 epoch(s).\n",
      "Epoch 25/100 — Train Loss: 20394.0572, Validation Loss: 21007.6527\n",
      "Learning rate: 0.000500\n",
      "Best model saved.\n",
      "Epoch 26/100 — Train Loss: 20321.9556, Validation Loss: 21481.6425\n",
      "Learning rate: 0.000500\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch 27/100 — Train Loss: 20452.2062, Validation Loss: 21707.8259\n",
      "Learning rate: 0.000500\n",
      "No improvement for 2 epoch(s).\n",
      "Epoch 28/100 — Train Loss: 20442.6233, Validation Loss: 20999.3856\n",
      "Learning rate: 0.000500\n",
      "Best model saved.\n",
      "Epoch 29/100 — Train Loss: 20289.4567, Validation Loss: 20837.3183\n",
      "Learning rate: 0.000500\n",
      "Best model saved.\n",
      "Epoch 30/100 — Train Loss: 20204.4241, Validation Loss: 20303.7341\n",
      "Learning rate: 0.000500\n",
      "Best model saved.\n",
      "Epoch 31/100 — Train Loss: 19518.8634, Validation Loss: 20183.2854\n",
      "Learning rate: 0.000500\n",
      "Best model saved.\n",
      "Epoch 32/100 — Train Loss: 19252.4116, Validation Loss: 19992.2418\n",
      "Learning rate: 0.000500\n",
      "Best model saved.\n",
      "Epoch 33/100 — Train Loss: 19203.1849, Validation Loss: 20099.8720\n",
      "Learning rate: 0.000500\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch 34/100 — Train Loss: 19423.0583, Validation Loss: 20323.1981\n",
      "Learning rate: 0.000500\n",
      "No improvement for 2 epoch(s).\n",
      "Epoch 35/100 — Train Loss: 19185.9087, Validation Loss: 20499.8997\n",
      "Learning rate: 0.000500\n",
      "No improvement for 3 epoch(s).\n",
      "Epoch 36/100 — Train Loss: 19186.0256, Validation Loss: 20069.8435\n",
      "Learning rate: 0.000500\n",
      "No improvement for 4 epoch(s).\n",
      "Epoch 37/100 — Train Loss: 19151.6704, Validation Loss: 20963.1627\n",
      "Learning rate: 0.000500\n",
      "No improvement for 5 epoch(s).\n",
      "Epoch 38/100 — Train Loss: 19043.5896, Validation Loss: 20149.0128\n",
      "Learning rate: 0.000250\n",
      "No improvement for 6 epoch(s).\n",
      "Epoch 39/100 — Train Loss: 18603.3447, Validation Loss: 20075.6264\n",
      "Learning rate: 0.000250\n",
      "No improvement for 7 epoch(s).\n",
      "Early stopping triggered after 39 epochs.\n"
     ]
    }
   ],
   "source": [
    "#############################################\n",
    "# Train the Squeezenet model \n",
    "#############################################\n",
    "squeezenet_models = train_deep_ensemble(num_models=5, model_name='squeezenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ab301c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SNR -> MAE: 100.1274, RMSE: 145.5695, R2: 0.6574\n",
      "SNR -> MAE: 100.1073, RMSE: 147.7848, R2: 0.6469\n",
      "SNR -> MAE: 101.5361, RMSE: 148.8427, R2: 0.6418\n",
      "SNR -> MAE: 101.3464, RMSE: 146.9787, R2: 0.6507\n",
      "SNR -> MAE: 94.2543, RMSE: 139.2030, R2: 0.6867\n"
     ]
    }
   ],
   "source": [
    "################################################\n",
    "# Results of each individual Squeezenet model\n",
    "################################################\n",
    "\n",
    "for i in range(5):\n",
    "    seed = 42\n",
    "    _, val_loader = get_data_loaders(seed=seed, test_ind=False, model_name='squeezenet')\n",
    "    evaluate_model(model=squeezenet_models[i], dataloader=val_loader, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de83cd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔁 Training model 1/5 with seed 42\n",
      "Epoch 1/100 — Train Loss: 54852.8147, Validation Loss: 61337.8161\n",
      "Learning rate: 0.001000\n",
      "Best model saved.\n",
      "Epoch 2/100 — Train Loss: 53326.5396, Validation Loss: 59946.9681\n",
      "Learning rate: 0.001000\n",
      "Best model saved.\n",
      "Epoch 3/100 — Train Loss: 53266.7510, Validation Loss: 164628.3750\n",
      "Learning rate: 0.001000\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch 4/100 — Train Loss: 52578.3738, Validation Loss: 57924.0334\n",
      "Learning rate: 0.001000\n",
      "Best model saved.\n",
      "Epoch 5/100 — Train Loss: 51719.4950, Validation Loss: 56702.6766\n",
      "Learning rate: 0.001000\n",
      "Best model saved.\n",
      "Epoch 6/100 — Train Loss: 49994.5407, Validation Loss: 76025.3449\n",
      "Learning rate: 0.001000\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch 7/100 — Train Loss: 44353.6264, Validation Loss: 51655.7658\n",
      "Learning rate: 0.001000\n",
      "Best model saved.\n",
      "Epoch 8/100 — Train Loss: 31616.4647, Validation Loss: 27470.4952\n",
      "Learning rate: 0.001000\n",
      "Best model saved.\n",
      "Epoch 9/100 — Train Loss: 23355.9703, Validation Loss: 84142.3860\n",
      "Learning rate: 0.001000\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch 10/100 — Train Loss: 23058.7451, Validation Loss: 125868.6225\n",
      "Learning rate: 0.001000\n",
      "No improvement for 2 epoch(s).\n",
      "Epoch 11/100 — Train Loss: 19972.7382, Validation Loss: 42252.8818\n",
      "Learning rate: 0.001000\n",
      "No improvement for 3 epoch(s).\n",
      "Epoch 12/100 — Train Loss: 19469.2300, Validation Loss: 45138.3735\n",
      "Learning rate: 0.001000\n",
      "No improvement for 4 epoch(s).\n",
      "Epoch 13/100 — Train Loss: 20062.8252, Validation Loss: 20519.8307\n",
      "Learning rate: 0.001000\n",
      "Best model saved.\n",
      "Epoch 14/100 — Train Loss: 19286.7143, Validation Loss: 94736.7383\n",
      "Learning rate: 0.001000\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch 15/100 — Train Loss: 19149.5291, Validation Loss: 21847.2976\n",
      "Learning rate: 0.001000\n",
      "No improvement for 2 epoch(s).\n",
      "Epoch 16/100 — Train Loss: 19221.0958, Validation Loss: 21484.6880\n",
      "Learning rate: 0.001000\n",
      "No improvement for 3 epoch(s).\n",
      "Epoch 17/100 — Train Loss: 19108.4810, Validation Loss: 57760.6725\n",
      "Learning rate: 0.001000\n",
      "No improvement for 4 epoch(s).\n",
      "Epoch 18/100 — Train Loss: 18843.2002, Validation Loss: 24883.2453\n",
      "Learning rate: 0.001000\n",
      "No improvement for 5 epoch(s).\n",
      "Epoch 19/100 — Train Loss: 18676.4422, Validation Loss: 19452.4471\n",
      "Learning rate: 0.001000\n",
      "Best model saved.\n",
      "Epoch 20/100 — Train Loss: 19407.5378, Validation Loss: 50423.9901\n",
      "Learning rate: 0.001000\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch 21/100 — Train Loss: 19249.1990, Validation Loss: 22417.0305\n",
      "Learning rate: 0.001000\n",
      "No improvement for 2 epoch(s).\n",
      "Epoch 22/100 — Train Loss: 19191.3101, Validation Loss: 32423.1328\n",
      "Learning rate: 0.001000\n",
      "No improvement for 3 epoch(s).\n",
      "Epoch 23/100 — Train Loss: 18669.1579, Validation Loss: 20682.9896\n",
      "Learning rate: 0.001000\n",
      "No improvement for 4 epoch(s).\n",
      "Epoch 24/100 — Train Loss: 18469.4166, Validation Loss: 59560.1235\n",
      "Learning rate: 0.001000\n",
      "No improvement for 5 epoch(s).\n",
      "Epoch 25/100 — Train Loss: 18542.3446, Validation Loss: 61436.2612\n",
      "Learning rate: 0.000500\n",
      "No improvement for 6 epoch(s).\n",
      "Epoch 26/100 — Train Loss: 18054.7311, Validation Loss: 20981.8040\n",
      "Learning rate: 0.000500\n",
      "No improvement for 7 epoch(s).\n",
      "Early stopping triggered after 26 epochs.\n",
      "\n",
      "🔁 Training model 2/5 with seed 43\n",
      "Epoch 1/100 — Train Loss: 56434.8565, Validation Loss: 57567.4379\n",
      "Learning rate: 0.001000\n",
      "Best model saved.\n",
      "Epoch 2/100 — Train Loss: 55184.0659, Validation Loss: 55856.5005\n",
      "Learning rate: 0.001000\n",
      "Best model saved.\n",
      "Epoch 3/100 — Train Loss: 54580.1086, Validation Loss: 54904.2399\n",
      "Learning rate: 0.001000\n",
      "Best model saved.\n",
      "Epoch 4/100 — Train Loss: 53779.2595, Validation Loss: 54188.4884\n",
      "Learning rate: 0.001000\n",
      "Best model saved.\n",
      "Epoch 5/100 — Train Loss: 52708.3881, Validation Loss: 52466.6231\n",
      "Learning rate: 0.001000\n",
      "Best model saved.\n",
      "Epoch 6/100 — Train Loss: 49916.1732, Validation Loss: 48630.4150\n",
      "Learning rate: 0.001000\n",
      "Best model saved.\n",
      "Epoch 7/100 — Train Loss: 40982.1862, Validation Loss: 36168.5718\n",
      "Learning rate: 0.001000\n",
      "Best model saved.\n",
      "Epoch 8/100 — Train Loss: 29969.7583, Validation Loss: 65273.3234\n",
      "Learning rate: 0.001000\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch 9/100 — Train Loss: 22183.9839, Validation Loss: 67381.8762\n",
      "Learning rate: 0.001000\n",
      "No improvement for 2 epoch(s).\n",
      "Epoch 10/100 — Train Loss: 21525.3918, Validation Loss: 21307.1989\n",
      "Learning rate: 0.001000\n",
      "Best model saved.\n",
      "Epoch 11/100 — Train Loss: 21318.9008, Validation Loss: 81003.3939\n",
      "Learning rate: 0.001000\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch 12/100 — Train Loss: 20515.3745, Validation Loss: 55073.7561\n",
      "Learning rate: 0.001000\n",
      "No improvement for 2 epoch(s).\n",
      "Epoch 13/100 — Train Loss: 19577.3951, Validation Loss: 119403.8768\n",
      "Learning rate: 0.001000\n",
      "No improvement for 3 epoch(s).\n",
      "Epoch 14/100 — Train Loss: 19816.6597, Validation Loss: 127933.8864\n",
      "Learning rate: 0.001000\n",
      "No improvement for 4 epoch(s).\n",
      "Epoch 15/100 — Train Loss: 19904.8787, Validation Loss: 68218.4624\n",
      "Learning rate: 0.001000\n",
      "No improvement for 5 epoch(s).\n",
      "Epoch 16/100 — Train Loss: 19086.7564, Validation Loss: 53695.4884\n",
      "Learning rate: 0.000500\n",
      "No improvement for 6 epoch(s).\n",
      "Epoch 17/100 — Train Loss: 19290.1853, Validation Loss: 55043.3384\n",
      "Learning rate: 0.000500\n",
      "No improvement for 7 epoch(s).\n",
      "Early stopping triggered after 17 epochs.\n",
      "\n",
      "🔁 Training model 3/5 with seed 44\n",
      "Epoch 1/100 — Train Loss: 53610.0289, Validation Loss: 72524.3316\n",
      "Learning rate: 0.001000\n",
      "Best model saved.\n",
      "Epoch 2/100 — Train Loss: 52337.2914, Validation Loss: 64782.1826\n",
      "Learning rate: 0.001000\n",
      "Best model saved.\n",
      "Epoch 3/100 — Train Loss: 52111.0609, Validation Loss: 65183.6520\n",
      "Learning rate: 0.001000\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch 4/100 — Train Loss: 51527.7947, Validation Loss: 63583.3312\n",
      "Learning rate: 0.001000\n",
      "Best model saved.\n",
      "Epoch 5/100 — Train Loss: 50272.0762, Validation Loss: 60749.0405\n",
      "Learning rate: 0.001000\n",
      "Best model saved.\n",
      "Epoch 6/100 — Train Loss: 46835.6327, Validation Loss: 68483.5566\n",
      "Learning rate: 0.001000\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch 7/100 — Train Loss: 39956.2055, Validation Loss: 46131.4651\n",
      "Learning rate: 0.001000\n",
      "Best model saved.\n",
      "Epoch 8/100 — Train Loss: 28662.3739, Validation Loss: 31324.8223\n",
      "Learning rate: 0.001000\n",
      "Best model saved.\n",
      "Epoch 9/100 — Train Loss: 23030.9268, Validation Loss: 30728.0470\n",
      "Learning rate: 0.001000\n",
      "Best model saved.\n",
      "Epoch 10/100 — Train Loss: 20372.1786, Validation Loss: 50934.2476\n",
      "Learning rate: 0.001000\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch 11/100 — Train Loss: 19353.3224, Validation Loss: 36404.2663\n",
      "Learning rate: 0.001000\n",
      "No improvement for 2 epoch(s).\n",
      "Epoch 12/100 — Train Loss: 19312.0275, Validation Loss: 48350.9172\n",
      "Learning rate: 0.001000\n",
      "No improvement for 3 epoch(s).\n",
      "Epoch 13/100 — Train Loss: 19656.6253, Validation Loss: 20992.5202\n",
      "Learning rate: 0.001000\n",
      "Best model saved.\n",
      "Epoch 14/100 — Train Loss: 20296.7056, Validation Loss: 29935.8089\n",
      "Learning rate: 0.001000\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch 15/100 — Train Loss: 19657.4632, Validation Loss: 23889.9893\n",
      "Learning rate: 0.001000\n",
      "No improvement for 2 epoch(s).\n",
      "Epoch 16/100 — Train Loss: 18939.3668, Validation Loss: 22700.8395\n",
      "Learning rate: 0.001000\n",
      "No improvement for 3 epoch(s).\n",
      "Epoch 17/100 — Train Loss: 18669.8726, Validation Loss: 27602.2528\n",
      "Learning rate: 0.001000\n",
      "No improvement for 4 epoch(s).\n",
      "Epoch 18/100 — Train Loss: 19169.4774, Validation Loss: 48899.3456\n",
      "Learning rate: 0.001000\n",
      "No improvement for 5 epoch(s).\n",
      "Epoch 19/100 — Train Loss: 18888.5300, Validation Loss: 101592.1233\n",
      "Learning rate: 0.000500\n",
      "No improvement for 6 epoch(s).\n",
      "Epoch 20/100 — Train Loss: 18396.3897, Validation Loss: 23337.4787\n",
      "Learning rate: 0.000500\n",
      "No improvement for 7 epoch(s).\n",
      "Early stopping triggered after 20 epochs.\n",
      "\n",
      "🔁 Training model 4/5 with seed 45\n",
      "Epoch 1/100 — Train Loss: 58003.2960, Validation Loss: 52082.4471\n",
      "Learning rate: 0.001000\n",
      "Best model saved.\n",
      "Epoch 2/100 — Train Loss: 56349.4236, Validation Loss: 50852.6281\n",
      "Learning rate: 0.001000\n",
      "Best model saved.\n",
      "Epoch 3/100 — Train Loss: 56269.6137, Validation Loss: 48209.1200\n",
      "Learning rate: 0.001000\n",
      "Best model saved.\n",
      "Epoch 4/100 — Train Loss: 55426.7956, Validation Loss: 48190.4142\n",
      "Learning rate: 0.001000\n",
      "Best model saved.\n",
      "Epoch 5/100 — Train Loss: 54511.9578, Validation Loss: 45329.7249\n",
      "Learning rate: 0.001000\n",
      "Best model saved.\n",
      "Epoch 6/100 — Train Loss: 52883.9052, Validation Loss: 44298.9676\n",
      "Learning rate: 0.001000\n",
      "Best model saved.\n",
      "Epoch 7/100 — Train Loss: 47246.3453, Validation Loss: 35795.0423\n",
      "Learning rate: 0.001000\n",
      "Best model saved.\n",
      "Epoch 8/100 — Train Loss: 35557.0898, Validation Loss: 27228.1542\n",
      "Learning rate: 0.001000\n",
      "Best model saved.\n",
      "Epoch 9/100 — Train Loss: 23980.0017, Validation Loss: 63786.3501\n",
      "Learning rate: 0.001000\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch 10/100 — Train Loss: 22265.7721, Validation Loss: 21085.4115\n",
      "Learning rate: 0.001000\n",
      "Best model saved.\n",
      "Epoch 11/100 — Train Loss: 20408.0349, Validation Loss: 50099.4939\n",
      "Learning rate: 0.001000\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch 12/100 — Train Loss: 20604.7355, Validation Loss: 23426.1542\n",
      "Learning rate: 0.001000\n",
      "No improvement for 2 epoch(s).\n",
      "Epoch 13/100 — Train Loss: 19474.6114, Validation Loss: 23122.3989\n",
      "Learning rate: 0.001000\n",
      "No improvement for 3 epoch(s).\n",
      "Epoch 14/100 — Train Loss: 20092.8516, Validation Loss: 34166598.0870\n",
      "Learning rate: 0.001000\n",
      "No improvement for 4 epoch(s).\n",
      "Epoch 15/100 — Train Loss: 21320.6629, Validation Loss: 24584.0997\n",
      "Learning rate: 0.001000\n",
      "No improvement for 5 epoch(s).\n",
      "Epoch 16/100 — Train Loss: 21452.9338, Validation Loss: 21086.6907\n",
      "Learning rate: 0.000500\n",
      "No improvement for 6 epoch(s).\n",
      "Epoch 17/100 — Train Loss: 20111.3153, Validation Loss: 31152.8856\n",
      "Learning rate: 0.000500\n",
      "No improvement for 7 epoch(s).\n",
      "Early stopping triggered after 17 epochs.\n",
      "\n",
      "🔁 Training model 5/5 with seed 46\n",
      "Epoch 1/100 — Train Loss: 56906.9215, Validation Loss: 53655.2084\n",
      "Learning rate: 0.001000\n",
      "Best model saved.\n",
      "Epoch 2/100 — Train Loss: 55230.7248, Validation Loss: 550377.3308\n",
      "Learning rate: 0.001000\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch 3/100 — Train Loss: 55077.0347, Validation Loss: 70847.9305\n",
      "Learning rate: 0.001000\n",
      "No improvement for 2 epoch(s).\n",
      "Epoch 4/100 — Train Loss: 54327.4514, Validation Loss: 52457.8187\n",
      "Learning rate: 0.001000\n",
      "Best model saved.\n",
      "Epoch 5/100 — Train Loss: 53855.4641, Validation Loss: 556535.5824\n",
      "Learning rate: 0.001000\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch 6/100 — Train Loss: 52896.1568, Validation Loss: 56445.5005\n",
      "Learning rate: 0.001000\n",
      "No improvement for 2 epoch(s).\n",
      "Epoch 7/100 — Train Loss: 50001.1289, Validation Loss: 45731.9542\n",
      "Learning rate: 0.001000\n",
      "Best model saved.\n",
      "Epoch 8/100 — Train Loss: 43456.8262, Validation Loss: 87527.2275\n",
      "Learning rate: 0.001000\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch 9/100 — Train Loss: 30254.3023, Validation Loss: 28862.6351\n",
      "Learning rate: 0.001000\n",
      "Best model saved.\n",
      "Epoch 10/100 — Train Loss: 23806.5882, Validation Loss: 76757.0460\n",
      "Learning rate: 0.001000\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch 11/100 — Train Loss: 20262.7444, Validation Loss: 93138.2347\n",
      "Learning rate: 0.001000\n",
      "No improvement for 2 epoch(s).\n",
      "Epoch 12/100 — Train Loss: 20542.2372, Validation Loss: 869555.6630\n",
      "Learning rate: 0.001000\n",
      "No improvement for 3 epoch(s).\n",
      "Epoch 13/100 — Train Loss: 20147.6030, Validation Loss: 1128807.1630\n",
      "Learning rate: 0.001000\n",
      "No improvement for 4 epoch(s).\n",
      "Epoch 14/100 — Train Loss: 19274.6375, Validation Loss: 1413392632.5797\n",
      "Learning rate: 0.001000\n",
      "No improvement for 5 epoch(s).\n",
      "Epoch 15/100 — Train Loss: 19817.8320, Validation Loss: 21851.6944\n",
      "Learning rate: 0.001000\n",
      "Best model saved.\n",
      "Epoch 16/100 — Train Loss: 19479.0293, Validation Loss: 26689.7668\n",
      "Learning rate: 0.001000\n",
      "No improvement for 1 epoch(s).\n",
      "Epoch 17/100 — Train Loss: 19208.8142, Validation Loss: 76958.5735\n",
      "Learning rate: 0.001000\n",
      "No improvement for 2 epoch(s).\n",
      "Epoch 18/100 — Train Loss: 19183.0010, Validation Loss: 82625183.1884\n",
      "Learning rate: 0.001000\n",
      "No improvement for 3 epoch(s).\n",
      "Epoch 19/100 — Train Loss: 19470.0731, Validation Loss: 425528121.0435\n",
      "Learning rate: 0.001000\n",
      "No improvement for 4 epoch(s).\n",
      "Epoch 20/100 — Train Loss: 18759.7989, Validation Loss: 22697.9118\n",
      "Learning rate: 0.001000\n",
      "No improvement for 5 epoch(s).\n",
      "Epoch 21/100 — Train Loss: 19114.9305, Validation Loss: 169238608.9275\n",
      "Learning rate: 0.000500\n",
      "No improvement for 6 epoch(s).\n",
      "Epoch 22/100 — Train Loss: 18415.9193, Validation Loss: 17557413531.8261\n",
      "Learning rate: 0.000500\n",
      "No improvement for 7 epoch(s).\n",
      "Early stopping triggered after 22 epochs.\n"
     ]
    }
   ],
   "source": [
    "#############################################\n",
    "# Train the densenet model \n",
    "#############################################\n",
    "densenet_models = train_deep_ensemble(num_models=5, model_name='densenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74809a3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SNR -> MAE: 101.9847, RMSE: 144.8510, R2: 0.6608\n",
      "SNR -> MAE: 184.5575, RMSE: 234.6132, R2: 0.0330\n",
      "SNR -> MAE: 104.3289, RMSE: 152.7661, R2: 0.6503\n",
      "SNR -> MAE: 133.2465, RMSE: 176.5018, R2: 0.3771\n",
      "SNR -> MAE: 123571.7500, RMSE: 132504.3906, R2: -323457.9150\n"
     ]
    }
   ],
   "source": [
    "################################################\n",
    "# Results of each individual Densenet model\n",
    "################################################\n",
    "\n",
    "for i in range(5):\n",
    "    seed = 42+i\n",
    "    _, val_loader = get_data_loaders(seed=seed, test_ind=False, model_name='densenet')\n",
    "    evaluate_model(model=densenet_models[i], dataloader=val_loader, device='cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76bbb23",
   "metadata": {},
   "source": [
    "Among the results of other baseline models trained above, ResNet and Squeezenet models will only be used for comparison since the Densenet model is not stable in terms of results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00478a8",
   "metadata": {},
   "source": [
    "| Architecture     | Epochs | MAE      | RMSE     | R²     |\n",
    "|------------------|--------|----------|----------|--------|\n",
    "| CAPRI-CT (ours)  | 54     | 68.0280  | 106.4930 | 0.7990 |\n",
    "| CNN              | 26     | 94.7015  | 141.2704 | 0.6773 |\n",
    "| ResNet           | 93     | 89.3858  | 129.1232 | 0.7502 |\n",
    "| SqueezeNet       | 93     | 94.2543  | 139.2030 | 0.6867 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41cc035",
   "metadata": {},
   "source": [
    "We compared the proposed CAPRI-CT framework against several baseline models, including CNN Baseline, ResNet and SqueezeNet. Among the baseline models, SqueezeNet demonstrated the most stable performance across all five folds. The model’s MAE values ranged narrowly from 91.45 to 102.93, and RMSE values from 140.08 to 148.71. The R2 scores also remained consistent, varying between 0.608 and 0.669."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
